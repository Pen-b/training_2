{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graphs Part 1: Rule-Based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This article demonstrates how to construct a knowledge graph using rule based methods. \n",
    "\n",
    "Knowledge graphs organise data from multiple sources, capturing information about entities of interest in a given domain or task (like people, places or events), and forge connections between them. They have become critical tools in many data heavy fields such as biomedical research and drug discovery, materials science, recommendation systems, intelligence gathering and political risk among others. Knowledge graphs are increasingly the focus of machine-learning and data-mining research efforts toward human-level computational cognition and intelligence.[wiki](https://en.wikipedia.org/wiki/Knowledge_graph)\n",
    "\n",
    "- [Hogan, 2021. Introduction to Knowledge Graphs, ACM Reviews](https://dl.acm.org/doi/abs/10.1145/3447772)\n",
    "- [A Survey on Knowledge Graphs: Representation, Acquisition and Applications](https://arxiv.org/abs/2002.00388)\n",
    "\n",
    "\n",
    "Knowledge graphs use a graph-data structure to integrate data using:\n",
    "1. Entities, the \"things\" of interest - represented as nodes. \n",
    "1. Relationships, the attributes and relationships between entities - represented as edges. \n",
    "\n",
    "As an example, consider this diagram about the some of the main entities in The Mandolorian television series and how they relate to one another.\n",
    "\n",
    "<img src=\"./kg-example.png\" width=600 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are knowledge graphs constructed?\n",
    "\n",
    "Text-mining and Natural Language Processing (NLP) techniques are used to process raw text into a knowledge graph structure. A typical pipeline will involve:\n",
    "\n",
    "1.  **Entity Extraction:** the entities of interest are identified and captured from within the text data.\n",
    "\n",
    "1. **Coreference Resolution:** the task of finding all mentions of the same entity within a text. For instance, if the entity \"Luke Skywalker\" is later referenced by a personal pronoun \"He is a Jedi\".\n",
    "\n",
    "1. **Relationship Extraction:** This step identifies what kind of relationship, if any, exists between any two entities.\n",
    "\n",
    "Each step can be achieved using rule-based methods (e.g. Regex patterns), and or machine-learning methods (e.g. Named Entity Recognition). \n",
    "\n",
    "<img src=\"./nlp-pipeline.png\" width=600 height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "85600930b325b2bc99c604b7535cf298e475c247"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "I have manually grabbed some example news articles for this excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  [\n",
    "    # https://www.bbc.co.uk/news/world-us-canada-60177979\n",
    "    (\n",
    "        \"The US East Coast is hunkering down as a major blizzard hits the region for the first time in four years.\"\n",
    "        \"The storm is forecast to stretch from the Carolinas to Maine, packing hurricane-force winds in coastal parts.\"\n",
    "        \"Five states have declared emergencies.\"\n",
    "        \"Mayor Michelle Wu of Boston, a city that is no stranger to snowfall, said the storm could be 'historic'.\"\n",
    "        \"More than two feet of snow could fall in New England.\"\n",
    "        \"Weather officials also warn of flooding near the coast.\"\n",
    "        \"Over 5,000 US flights were cancelled between Friday and Sunday, according to FlightAware.\"\n",
    "        \"Forecasters say there is a chance the storm, known as a Nor\\'easter, will blanket the Boston area with up to 2ft (61cm) of snow.\"\n",
    "        ),\n",
    "    # https://www.bbc.co.uk/news/business-60163814\n",
    "    (  \n",
    "        \"Apple sales soared in the key Christmas shopping season, despite constraints due to a global shortage of microchips.\"\n",
    "        \"Sales at the iPhone giant rose 11% to a record $123.9bn (Â£92.6bn) in the October to December period, beating forecasts.\"\n",
    "        \"Shares jumped more than 4% in after-hours trade, as the report suggested the firm's pandemic boom is continuing.\"\n",
    "        \"Apple has seen purchases skyrocket during the pandemic as people spend more time online.\"\n",
    "        \"The firm's market value briefly hit the $3tn milestone in early January though its share price has slipped more recently amid weeks of market turmoil.\"\n",
    "        ),\n",
    "    # https://news.sky.com/story/staycation-frenzy-spurs-center-parcs-owner-to-prepare-4bn-sale-12527982\n",
    "    (\n",
    "        \"Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year.\"\n",
    "        \"City sources said this weekend that Brookfield had engaged the accountancy firm PriceWaterhouseCoopers to assist with preparations for a sale process.\"\n",
    "        \"Investment banks have yet to be formally appointed to handle an auction, and one person close to the process said it was possible that Brookfield would decide to retain the business for a longer period if it did not secure a sufficiently attractive offer.\"\n",
    "        \"Center Parcs is one of the most famous brands in the British leisure industry, drawing millions of visitors annually to its five UK sites and the latest addition to its portfolio, at Longford Forest in Ireland.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2099872afd539fa28784a066f2ce0c06c42a2585"
   },
   "source": [
    "##  Pipeline\n",
    "\n",
    "We can build a basic relation-extraction process by analysing the grammatical and \"part of speech\" patterns to identify related nouns within a text. A simple rule might be:\n",
    "\n",
    "```\n",
    "Proper Noun - Verb - Proper Noun\n",
    "```\n",
    "\n",
    "In computational linguistics, a part-of-speech (POS) tag is used to categorise the grammatical properties of words in a text. For instance, nouns (people, places and objects), adjectives that describe nouns (tall, smart, large, round), verbs that describe actions (driving, running, selling, talking), and so on. Natural Language Processing (NLP) models can be used to predict and classify POS tags on a given text, by applying linguistic rules and machine learning models to evaluate word position and context. Popular NLP packages, such as NLTK and spaCy, include this functionality. To read more about POS, see this [POS summary](https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba); the spaCy [documentation](https://spacy.io/usage/linguistic-features#pos-tagging), [python script](https://github.com/explosion/spaCy/blob/master/spacy/glossary.py,) and [SO explanation](https://stackoverflow.com/questions/40288323/what-do-spacys-part-of-speech-and-dependency-tags-mean); and this [POS tag reference list](https://sites.google.com/site/partofspeechhelp/#TOC-Welcome).\n",
    "\n",
    "> **NOTE:**\n",
    "spaCy uses the terms *head* and *child* to describe the words connected by a single arc in the dependency tree. The term *dep* is used for the arc label, which describes the type of syntactic relation that connects the child to the head.\n",
    "\n",
    "\n",
    "Using spaCy, we can iterate over each sentence and identify where the POS pattern `NOUN-VERB-NOUN` occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "fd80efd1e651449ee42847f5859feadea27a15ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[US, hunkering, blizzard] \n",
      " US (NNP|compound) East (NNP|compound) Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      " The US East Coast is hunkering down as a major blizzard hits the region for the first time in four years. \n",
      "\n",
      "[East, hunkering, blizzard] \n",
      " East (NNP|compound) Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      " The US East Coast is hunkering down as a major blizzard hits the region for the first time in four years. \n",
      "\n",
      "[Coast, hunkering, blizzard] \n",
      " Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      " The US East Coast is hunkering down as a major blizzard hits the region for the first time in four years. \n",
      "\n",
      "[Apple, soared, Christmas] \n",
      " Apple (NN|compound) sales (NNS|nsubj) soared (VBD|ROOT) in (IN|prep) the (DT|det) key (JJ|amod) Christmas (NNP|compound) \n",
      " Apple sales soared in the key Christmas shopping season, despite constraints due to a global shortage of microchips. \n",
      "\n",
      "[sales, soared, Christmas] \n",
      " sales (NNS|nsubj) soared (VBD|ROOT) in (IN|prep) the (DT|det) key (JJ|amod) Christmas (NNP|compound) \n",
      " Apple sales soared in the key Christmas shopping season, despite constraints due to a global shortage of microchips. \n",
      "\n",
      "[Sky, learnt, Brookfield] \n",
      " Sky (NNP|compound) News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield (NNP|compound) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[News, learnt, Brookfield] \n",
      " News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield (NNP|compound) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[Brookfield, paving, way] \n",
      " Brookfield (NNP|compound) Property (NNP|compound) Partners (NNPS|nsubj) , (,|punct) the (DT|det) Canadian (JJ|amod) property (NN|compound) giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the (DT|det) way (NN|dobj) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[Property, paving, way] \n",
      " Property (NNP|compound) Partners (NNPS|nsubj) , (,|punct) the (DT|det) Canadian (JJ|amod) property (NN|compound) giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the (DT|det) way (NN|dobj) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[property, paving, way] \n",
      " property (NN|compound) giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the (DT|det) way (NN|dobj) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[giant, paving, way] \n",
      " giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the (DT|det) way (NN|dobj) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "[way, sell, Center] \n",
      " way (NN|dobj) to (TO|aux) sell (VB|relcl) Center (NNP|compound) \n",
      " Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns = ['NNP','NN','NNS']\n",
    "verbs = [\"VB\",\"VBG\"]\n",
    "relations = list()\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    for e,sent in enumerate(doc.sents):\n",
    "        chain = list()\n",
    "        for a in sent:\n",
    "            if a.tag_ in nouns: # find first NOUND\n",
    "                chain.append(a)\n",
    "                for b in sent[a.i:]: # find ROOT, alternatively VERBS\n",
    "                    if (b.dep_ == 'ROOT') or (b.tag_ in verbs) and len(chain) == 1:\n",
    "                        chain.append(b)\n",
    "                        for c in sent[b.i:]: # find second NOUN\n",
    "                            if c.tag_ in nouns and len(chain) == 2: \n",
    "                                chain.append(c)\n",
    "                                \n",
    "                                # reset chain and print result\n",
    "                                relations.append(chain)\n",
    "                                pos_chain = ' '.join([f\"{i} ({i.tag_}|{i.dep_})\" for i in sent[a.i:c.i+1]])\n",
    "                                print(chain,'\\n',pos_chain,'\\n',sent,'\\n')\n",
    "                                chain = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this simple approach seems OK at finding basic entities and relations.\n",
    "\n",
    "- US --- **hunkering** ---> Blizzard\n",
    "- Sales --- **soared** ---> Christmas\n",
    "- Sky --- **learnt** ---> Brookfield\n",
    "\n",
    "The limitation and problem of this approach is that it relies on an extensive list of *Part-Of-Speech* tag patterns. This won't scale for most problems as nouns and verbs come in a wide variety of forms and with modifiers etc. For instance, you generally want to capture compound phrases and patterns such as:\n",
    "\n",
    "```\n",
    "US-East-Cost = NNP-NNP-NNP\n",
    "hunkering-down = VBG-RP\n",
    "major-blizzard = JJ-NN\n",
    "```\n",
    "\n",
    "To improve our method we can:\n",
    " 1. Use NLP techniques for noun-chunks and entity-recognition to better capture compound entity phrases.\n",
    " 1. Develop POS patterns and rules to identify and extract relations between two or more entities. \n",
    " \n",
    "\n",
    "### Entity Recognition\n",
    "\n",
    "A spaCy pipeline is constructed with components for Named Entity Recognition (NER) and Noun Chunks to capture entities. We could also define some sensible rules for the type of entities to include to control what information will be represented in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'merge_entities', 'merge_noun_chunks']\n",
      "\n",
      " Sky News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield Property Partners (NNPS|nsubj) , (,|punct) the Canadian property giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the way (NN|dobj) to (TO|aux) sell (VB|relcl) Center Parcs UK (NNP|dobj) potentially (RB|advmod) as (RB|advmod) soon (RB|advmod) as (IN|prep) this year (NN|pobj) . (.|punct) City sources (NNS|nsubj) said (VBD|ROOT) this weekend (NN|npadvmod) that (IN|mark) Brookfield (NNP|nsubj) had (VBD|aux) engaged (VBN|ccomp) the accountancy firm PriceWaterhouseCoopers (NNS|dobj) to (TO|aux) assist (VB|xcomp) with (IN|prep) preparations (NNS|pobj) for (IN|prep) a sale process (NN|pobj) . (.|punct) Investment banks (NNS|nsubj) have (VBP|ROOT) yet (RB|advmod) to (TO|aux) be (VB|auxpass) formally (RB|advmod) appointed (VBN|xcomp) to (TO|aux) handle (VB|xcomp) an auction (NN|dobj) , (,|punct) and (CC|cc) one person (NN|nsubj) close (JJ|amod) to (IN|prep) the process (NN|pobj) said (VBD|conj) it (PRP|nsubj) was (VBD|ccomp) possible (JJ|acomp) that (IN|mark) Brookfield (NNP|nsubj) would (MD|aux) decide (VB|ccomp) to (TO|aux) retain (VB|xcomp) the business (NN|dobj) for (IN|prep) a longer period (NN|pobj) if (IN|mark) it (PRP|nsubj) did (VBD|aux) not (RB|neg) secure (VB|advcl) a sufficiently attractive offer (NN|dobj) . (.|punct) Center Parcs (NNP|nsubj) is (VBZ|ROOT) one (CD|attr) of (IN|prep) the most famous brands (NNS|pobj) in (IN|prep) the British leisure industry (NN|pobj) , (,|punct) drawing (VBG|advcl) millions (NNS|dobj) of (IN|prep) visitors (NNS|pobj) annually (RB|advmod) to (IN|prep) its five UK sites (NNS|pobj) and (CC|cc) the (DT|det) latest (JJS|amod) addition (NN|conj) to (IN|prep) its portfolio (NN|pobj) , (,|punct) at (IN|prep) Longford Forest (NNP|pobj) in (IN|prep) Ireland (NNP|pobj) . (.|punct) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sky News\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has learnt that \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield Property Partners\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", the Canadian property giant, is paving the way to sell \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Center Parcs UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " potentially as soon as \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".City sources said \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this weekend\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " had engaged the accountancy firm PriceWaterhouseCoopers to assist with preparations for a sale process.Investment banks have yet to be formally appointed to handle an auction, and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one person\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " close to the process said it was possible that \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " would decide to retain the business for a longer period if it did not secure a sufficiently attractive offer.\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Center Parcs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the most famous brands in the British leisure industry, drawing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    millions\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of visitors \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    annually\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to its five UK sites and the latest addition to its portfolio, at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Longford Forest\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ireland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "\t Sky News ORG\n",
      "\t Brookfield Property Partners ORG\n",
      "\t Center Parcs UK ORG\n",
      "\t this year DATE\n",
      "\t this weekend DATE\n",
      "\t Brookfield GPE\n",
      "\t one person CARDINAL\n",
      "\t Brookfield GPE\n",
      "\t Center Parcs ORG\n",
      "\t one CARDINAL\n",
      "\t millions CARDINAL\n",
      "\t annually DATE\n",
      "\t Longford Forest ORG\n",
      "\t Ireland GPE\n",
      "Noun chunks:\n",
      "\t Sky News\n",
      "\t Brookfield Property Partners\n",
      "\t the Canadian property giant\n",
      "\t the way\n",
      "\t Center Parcs UK\n",
      "\t this year\n",
      "\t City sources\n",
      "\t Brookfield\n",
      "\t the accountancy firm PriceWaterhouseCoopers\n",
      "\t preparations\n",
      "\t a sale process\n",
      "\t Investment banks\n",
      "\t an auction\n",
      "\t one person\n",
      "\t the process\n",
      "\t it\n",
      "\t Brookfield\n",
      "\t the business\n",
      "\t a longer period\n",
      "\t it\n",
      "\t a sufficiently attractive offer\n",
      "\t Center Parcs\n",
      "\t the most famous brands\n",
      "\t the British leisure industry\n",
      "\t millions\n",
      "\t visitors\n",
      "\t its five UK sites\n",
      "\t its portfolio\n",
      "\t Longford Forest\n",
      "\t Ireland\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_noun_chunks\"))\n",
    "    print(nlp.pipe_names)\n",
    "except:\n",
    "    print(nlp.pipe_names)\n",
    "\n",
    "\n",
    "doc = nlp(texts[2])\n",
    "print('\\n', ' '.join([f\"{d} ({d.tag_}|{d.dep_})\" for d in doc]),'\\n')\n",
    "spacy.displacy.render(doc, style='ent')\n",
    "\n",
    "print('Entities:')\n",
    "for t in doc:\n",
    "    if t.ent_type_ != '': print('\\t',t,t.ent_type_)\n",
    "\n",
    "print('Noun chunks:')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('\\t',chunk.text, )\n",
    "    #chunk.root.text, chunk.root.dep_,chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a dictionary of noun-chunks and named-entities from doc. The dictionary index is the start-end span positions of the terms to remove and avoid any duplicates between noun-chunks and named-entities.\n",
    "\n",
    "Notice that, as it combines individual terms, the noun-chunk function obliterates e.g. \"Canadian\" being identified as a named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_entities(span,ent_types=None,noun_chunks=False):\n",
    "#     entities = dict()\n",
    "#     if ent_types is None:\n",
    "#         ent_types = ['ORG','PERSON','GPE','NORP','LOC','PRODUCT']\n",
    "        \n",
    "#     if noun_chunks:\n",
    "#         entities.update({int(f\"{i.start}{i.end}\"): {\"span\":i, \"type\":\"NOUN_CHUNK\"} for i in span.noun_chunks})\n",
    "        \n",
    "#     entities.update({int(f\"{i.start}{i.end}\"): {\"span\":i, \"type\":i.label_} for i in span.ents if i.label_ in ent_types})\n",
    "#     keys = sorted(entities)\n",
    "#     return entities, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(doc: spacy.tokens.doc.Doc,ent_types: list = None, noun_chunks: bool = True):\n",
    "    entities = dict()\n",
    "    \n",
    "    for enum,sent in enumerate(doc.sents):\n",
    "        \n",
    "        if noun_chunks:\n",
    "            entities.update({f\"{i.start}-{i.end}\": {\"sentence\":enum, \"span\":i, \"type\":\"NOUN_CHUNK\"} for i in sent.noun_chunks})\n",
    "\n",
    "        if ent_types is None:\n",
    "            ent_types = ['ORG','PERSON','GPE','NORP','LOC','PRODUCT']\n",
    "        entities.update({f\"{i.start}-{i.end}\": {\"sentence\":enum, \"span\":i, \"type\":i.label_} for i in sent.ents if i.label_ in ent_types})\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>span</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1</th>\n",
       "      <td>0</td>\n",
       "      <td>(Sky News)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-5</th>\n",
       "      <td>0</td>\n",
       "      <td>(Brookfield Property Partners)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-7</th>\n",
       "      <td>0</td>\n",
       "      <td>(the Canadian property giant)</td>\n",
       "      <td>NOUN_CHUNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-11</th>\n",
       "      <td>0</td>\n",
       "      <td>(the way)</td>\n",
       "      <td>NOUN_CHUNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-14</th>\n",
       "      <td>0</td>\n",
       "      <td>(Center Parcs UK)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence                            span        type\n",
       "0-1           0                      (Sky News)         ORG\n",
       "4-5           0  (Brookfield Property Partners)         ORG\n",
       "6-7           0   (the Canadian property giant)  NOUN_CHUNK\n",
       "10-11         0                       (the way)  NOUN_CHUNK\n",
       "13-14         0               (Center Parcs UK)         ORG"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = get_entities(doc)\n",
    "\n",
    "pd.DataFrame.from_dict(entities,orient='index')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Extraction\n",
    "\n",
    "Spacy's dependency parser operates on each sentence in isolation. Therefore it is **not possible** to extract relations across sentences using the rules based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"57784fa190124b6dbc38b1742d023bce-0\" class=\"displacy\" width=\"3025\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sky News</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learnt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Brookfield Property Partners,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the Canadian property giant,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">paving</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">the way</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">sell</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">Center Parcs UK</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">potentially</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">soon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">this year.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,89.5 1270.0,89.5 1270.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-3\" stroke-width=\"2px\" d=\"M770,439.5 C770,177.0 1265.0,177.0 1265.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M905.0,441.5 L913.0,429.5 897.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-5\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-6\" stroke-width=\"2px\" d=\"M420,439.5 C420,2.0 1275.0,2.0 1275.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,441.5 L1283.0,429.5 1267.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1430.0,441.5 L1438.0,429.5 1422.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-9\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,264.5 1785.0,264.5 1785.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,441.5 L1793.0,429.5 1777.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1955.0,441.5 L1963.0,429.5 1947.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-11\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,264.5 2135.0,264.5 2135.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,441.5 L2143.0,429.5 2127.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-13\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,89.5 2495.0,89.5 2495.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2495.0,441.5 L2503.0,429.5 2487.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-14\" stroke-width=\"2px\" d=\"M2520,439.5 C2520,352.0 2655.0,352.0 2655.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2655.0,441.5 L2663.0,429.5 2647.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-57784fa190124b6dbc38b1742d023bce-0-15\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,352.0 2830.0,352.0 2830.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-57784fa190124b6dbc38b1742d023bce-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2830.0,441.5 L2838.0,429.5 2822.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spacy.displacy.render(doc, style='ent')\n",
    "spacy.displacy.render(sent, style='dep',)\n",
    "# spacy.explain('attr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Direct relations\n",
    "\n",
    "Capture any nouns or entities that are \"syntactic children\" direct ascendants and decedents of others using the [n_lefts and n_rights functionality of SpaCy](https://spacy.io/usage/linguistic-features#navigating-around)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_relations(entities: dict):\n",
    "    ent_names = [v['span'].text for v in entities.values()]\n",
    "    relations = list()\n",
    "\n",
    "    for v in entities.values():\n",
    "        \n",
    "        if v['span'].n_lefts > 0:\n",
    "            lf = [i for i in v['span'].lefts if i.text in ent_names]\n",
    "            if len(lf) > 0: \n",
    "                relations.append((lf[0].text,'=IS',v['span'].text,'DIRECT'))\n",
    "        if v['span'].n_rights > 0:\n",
    "            rt = [i for i in v['span'].rights if i.text in ent_names]\n",
    "            if len(rt) > 0: \n",
    "                relations.append((v['span'].text,'=IS',rt[0].text,'DIRECT'))\n",
    "\n",
    "    if len(relations) > 0:\n",
    "        return relations\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brookfield Property Partners',\n",
       "  '=IS',\n",
       "  'the Canadian property giant',\n",
       "  'DIRECT')]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_relations = get_direct_relations(entities)\n",
    "if direct_relations is not None:\n",
    "        relations += direct_relations\n",
    "        \n",
    "relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few more rules we could add to expand and improve relationship capture. \n",
    "\n",
    "#### 2. Root verb and verb relations \n",
    "\n",
    "For each sentence, relations can be extracted by iterating through the entity pairs and noun chunks, and yielding the ROOT VERB and other VERB terms. \n",
    "\n",
    "**looking into verbs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      " Sky News (NNP|nsubj|0) has (VBZ|aux|1) learnt (VBN|ROOT|2) that (IN|mark|3) Brookfield Property Partners (NNPS|nsubj|4) , (,|punct|5) the Canadian property giant (NN|appos|6) , (,|punct|7) is (VBZ|aux|8) paving (VBG|ccomp|9) the way (NN|dobj|10) to (TO|aux|11) sell (VB|relcl|12) Center Parcs UK (NNP|dobj|13) potentially (RB|advmod|14) as (RB|advmod|15) soon (RB|advmod|16) as (IN|prep|17) this year (NN|pobj|18) . (.|punct|19) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = list(doc.sents)[0]\n",
    "# for sent in doc.sents: \n",
    "s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_}|{t.i})\" for t in sent])\n",
    "print(sent,'\\n\\n',s_term_pos,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the 'ancestor' function shows which term(s) a given term 'descends' from.\n",
    "- rights,lefts show the descended children terms for a given term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year. \n",
      "\n",
      "1 has VBZ aux\n",
      "has [(has, 'aux', 'VBZ')]\n",
      "has [learnt]\n",
      "[] []\n",
      "\n",
      "\n",
      "2 learnt VBN ROOT\n",
      "learnt [(Sky News, 'nsubj', 'NNP'), (has, 'aux', 'VBZ'), (learnt, 'ROOT', 'VBN'), (that, 'mark', 'IN'), (Brookfield Property Partners, 'nsubj', 'NNPS'), (,, 'punct', ','), (the Canadian property giant, 'appos', 'NN'), (,, 'punct', ','), (is, 'aux', 'VBZ'), (paving, 'ccomp', 'VBG'), (the way, 'dobj', 'NN'), (to, 'aux', 'TO'), (sell, 'relcl', 'VB'), (Center Parcs UK, 'dobj', 'NNP'), (potentially, 'advmod', 'RB'), (as, 'advmod', 'RB'), (soon, 'advmod', 'RB'), (as, 'prep', 'IN'), (this year, 'pobj', 'NN'), (., 'punct', '.')]\n",
      "learnt []\n",
      "[(Sky News, 'nsubj'), (has, 'aux')] [(paving, 'ccomp'), (., 'punct')]\n",
      "\n",
      "\n",
      "8 is VBZ aux\n",
      "is [(is, 'aux', 'VBZ')]\n",
      "is [paving, learnt]\n",
      "[] []\n",
      "\n",
      "\n",
      "9 paving VBG ccomp\n",
      "paving [(that, 'mark', 'IN'), (Brookfield Property Partners, 'nsubj', 'NNPS'), (,, 'punct', ','), (the Canadian property giant, 'appos', 'NN'), (,, 'punct', ','), (is, 'aux', 'VBZ'), (paving, 'ccomp', 'VBG'), (the way, 'dobj', 'NN'), (to, 'aux', 'TO'), (sell, 'relcl', 'VB'), (Center Parcs UK, 'dobj', 'NNP'), (potentially, 'advmod', 'RB'), (as, 'advmod', 'RB'), (soon, 'advmod', 'RB'), (as, 'prep', 'IN'), (this year, 'pobj', 'NN')]\n",
      "paving [learnt]\n",
      "[(that, 'mark'), (Brookfield Property Partners, 'nsubj'), (is, 'aux')] [(the way, 'dobj')]\n",
      "\n",
      "\n",
      "11 to TO aux\n",
      "to [(to, 'aux', 'TO')]\n",
      "to [sell, the way, paving, learnt]\n",
      "[] []\n",
      "\n",
      "\n",
      "12 sell VB relcl\n",
      "sell [(to, 'aux', 'TO'), (sell, 'relcl', 'VB'), (Center Parcs UK, 'dobj', 'NNP'), (potentially, 'advmod', 'RB'), (as, 'advmod', 'RB'), (soon, 'advmod', 'RB'), (as, 'prep', 'IN'), (this year, 'pobj', 'NN')]\n",
      "sell [the way, paving, learnt]\n",
      "[(to, 'aux')] [(Center Parcs UK, 'dobj'), (potentially, 'advmod'), (soon, 'advmod')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sent,'\\n')\n",
    "\n",
    "for t in sent:\n",
    "    if t.tag_ in ['VBZ','VBG','VBD','VB','VBN','VB','TO']:\n",
    "        v = t.i\n",
    "        print(t.i,t,t.tag_,t.dep_)\n",
    "        print(doc[v], [(w,w.dep_,w.tag_) for w in doc[v].subtree])\n",
    "        print(doc[v], [w for w in doc[v].ancestors])\n",
    "        print([(w,w.dep_) for w in doc[v].lefts],[(w,w.dep_) for w in doc[v].rights])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find Parent / dominant verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has learnt\n",
      "is paving\n",
      "to sell\n"
     ]
    }
   ],
   "source": [
    "for t in sent:\n",
    "    if t.tag_ in ['VBZ','VBG','VBD','VB','VBN','VB','TO']:\n",
    "        v = t.i\n",
    "        lf = [w.i for w in doc[v].lefts if w.dep_ == 'aux']\n",
    "        rf = [w.i for w in doc[v].rights if w.dep_ == 'aux']\n",
    "        \n",
    "        if len(lf) > 0:\n",
    "            print(doc[lf[0]:v+1])\n",
    "        if len(rf) > 0:\n",
    "            print(doc[rf[0]:v+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Subject and Object term dependency relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year.\n",
      "\n",
      " {'sentence': 0, 'span': Sky News, 'type': 'ORG'}\n",
      "\n",
      " {'sentence': 0, 'span': Brookfield Property Partners, 'type': 'ORG'}\n",
      "\n",
      " {'sentence': 0, 'span': the Canadian property giant, 'type': 'NOUN_CHUNK'}\n",
      "\n",
      " {'sentence': 0, 'span': the way, 'type': 'NOUN_CHUNK'}\n",
      "\n",
      " {'sentence': 0, 'span': Center Parcs UK, 'type': 'ORG'}\n",
      "\n",
      " {'sentence': 0, 'span': this year, 'type': 'NOUN_CHUNK'}\n"
     ]
    }
   ],
   "source": [
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "OBJECTS = [\"pobj\",\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
    "SUB_OBJ = SUBJECTS+OBJECTS\n",
    "\n",
    "feature = [  \"ROOT\",\n",
    "             \"aux\",\"relcl\",\n",
    "             \"acomp\", \"advcl\", \"advmod\", \"amod\", \"appos\", \"nn\", \"nmod\", \"ccomp\", \"complm\",\n",
    "             \"hmod\", \"infmod\", \"xcomp\", \"rcmod\", \"poss\",\" possessive\",\n",
    "             \"compound\",\n",
    "             \"prep\"\n",
    "          ]\n",
    "\n",
    "relations = list()\n",
    "    \n",
    "for enum,sent in enumerate(doc.sents):\n",
    "    if enum > 0:\n",
    "        break\n",
    "    print(enum,sent)\n",
    "        \n",
    "    sentence_entities = {i:v for i,v in entities.items() if v['sentence'] == enum}\n",
    "    \n",
    "    for e in sentence_entities.values():\n",
    "        print('\\n',e)\n",
    "#         prev = list()\n",
    "#         for t in doc[e['span'].end:sent.end]: # from entity to end of sentence\n",
    "            \n",
    "#             if t.dep_ in SUB_OBJ:#['pobj','nsubj','dojb']: \n",
    "#                 terms = doc[e['span'].end:t.i]\n",
    "#                 print(terms)\n",
    "#                 rels = [t for t in terms if t.dep_ in feature if t.idx not in prev]\n",
    "#                 prev.extend([x.idx for x in rels]) # previous terms\n",
    "                \n",
    "                \n",
    "#                 if len(rels) > 0:\n",
    "#                     rels = ' '.join([x.text for x in rels])\n",
    "#                     print('\\tr:',rels)\n",
    "\n",
    "#                     relations.append((e['span'].text,rels,t.text,'ENT_POS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ent_pos_relations(doc, sentence_entities):\n",
    "    \"\"\"\n",
    "    Entity to POS relations\n",
    "    \"\"\"\n",
    "    SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "    OBJECTS = [\"pobj\",\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
    "    SUB_OBJ = SUBJECTS+OBJECTS\n",
    "    \n",
    "    feature = [  \"ROOT\",\n",
    "                 \"aux\",\"relcl\",\n",
    "                 \"acomp\", \"advcl\", \"advmod\", \"amod\", \"appos\", \"nn\", \"nmod\", \"ccomp\", \"complm\",\n",
    "                 \"hmod\", \"infmod\", \"xcomp\", \"rcmod\", \"poss\",\" possessive\",\n",
    "                 \"compound\",\n",
    "                 \"prep\"\n",
    "              ]\n",
    "\n",
    "    relations = list()\n",
    "    for e in sentence_entities.values():\n",
    "        prev = list()\n",
    "        for t in doc[e['span'].end:sent.end]:\n",
    "            if t.dep_ in ['pobj','nsubj','dojb']: \n",
    "                terms = doc[e['span'].end:t.i]\n",
    "                rels = [t for t in terms if t.dep_ in feature if t.idx not in prev]\n",
    "                prev.extend([x.idx for x in rels]) # previous terms\n",
    "                \n",
    "                if len(rels) > 0:\n",
    "                    rels = ' '.join([x.text for x in rels])\n",
    "                    relations.append((e['span'].text,rels,t.text,'ENT_POS'))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sky News', 'has learnt', 'Brookfield Property Partners', 'ENT_POS'),\n",
       " ('Sky News',\n",
       "  'the Canadian property giant is paving to sell potentially as soon as',\n",
       "  'this year',\n",
       "  'ENT_POS'),\n",
       " ('Sky News', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('Sky News', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('Sky News', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('Brookfield Property Partners',\n",
       "  'the Canadian property giant is paving to sell potentially as soon as',\n",
       "  'this year',\n",
       "  'ENT_POS'),\n",
       " ('Brookfield Property Partners', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('Brookfield Property Partners',\n",
       "  'had engaged to assist with',\n",
       "  'preparations',\n",
       "  'ENT_POS'),\n",
       " ('Brookfield Property Partners', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('the Canadian property giant',\n",
       "  'is paving to sell potentially as soon as',\n",
       "  'this year',\n",
       "  'ENT_POS'),\n",
       " ('the Canadian property giant', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('the Canadian property giant',\n",
       "  'had engaged to assist with',\n",
       "  'preparations',\n",
       "  'ENT_POS'),\n",
       " ('the Canadian property giant', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('the way', 'to sell potentially as soon as', 'this year', 'ENT_POS'),\n",
       " ('the way', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('the way', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('the way', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('Center Parcs UK', 'potentially as soon as', 'this year', 'ENT_POS'),\n",
       " ('Center Parcs UK', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('Center Parcs UK', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('Center Parcs UK', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('this year', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('this year', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('this year', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('City sources', 'said', 'Brookfield', 'ENT_POS'),\n",
       " ('City sources', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('City sources', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('Brookfield', 'had engaged to assist with', 'preparations', 'ENT_POS'),\n",
       " ('Brookfield', 'for', 'a sale process', 'ENT_POS'),\n",
       " ('the accountancy firm PriceWaterhouseCoopers',\n",
       "  'to assist with',\n",
       "  'preparations',\n",
       "  'ENT_POS'),\n",
       " ('the accountancy firm PriceWaterhouseCoopers',\n",
       "  'for',\n",
       "  'a sale process',\n",
       "  'ENT_POS'),\n",
       " ('preparations', 'for', 'a sale process', 'ENT_POS')]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ent_pos_relations(doc,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield Property Partners (NNPS|nsubj) , (,|punct) the Canadian property giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the way (NN|dobj) to (TO|aux) sell (VB|relcl) Center Parcs UK (NNP|dobj) potentially (RB|advmod) as (RB|advmod) soon (RB|advmod) as (IN|prep) this year (NN|pobj) . (.|punct)\n",
      "\t ('Sky News', 'has learnt', 'Brookfield Property Partners', 'ENT_POS')\n",
      "\t ('Sky News', 'the Canadian property giant is paving to sell potentially as soon as', 'this year', 'ENT_POS')\n",
      "\t ('Brookfield Property Partners', 'the Canadian property giant is paving to sell potentially as soon as', 'this year', 'ENT_POS')\n",
      "\t ('the Canadian property giant', 'is paving to sell potentially as soon as', 'this year', 'ENT_POS')\n",
      "\t ('the way', 'to sell potentially as soon as', 'this year', 'ENT_POS')\n",
      "\t ('Center Parcs UK', 'potentially as soon as', 'this year', 'ENT_POS')\n",
      "City sources (NNS|nsubj) said (VBD|ROOT) this weekend (NN|npadvmod) that (IN|mark) Brookfield (NNP|nsubj) had (VBD|aux) engaged (VBN|ccomp) the accountancy firm PriceWaterhouseCoopers (NNS|dobj) to (TO|aux) assist (VB|xcomp) with (IN|prep) preparations (NNS|pobj) for (IN|prep) a sale process (NN|pobj) . (.|punct)\n",
      "\t ('City sources', 'said', 'Brookfield', 'ENT_POS')\n",
      "\t ('City sources', 'had engaged to assist with', 'preparations', 'ENT_POS')\n",
      "\t ('City sources', 'for', 'a sale process', 'ENT_POS')\n",
      "\t ('Brookfield', 'had engaged to assist with', 'preparations', 'ENT_POS')\n",
      "\t ('Brookfield', 'for', 'a sale process', 'ENT_POS')\n",
      "\t ('the accountancy firm PriceWaterhouseCoopers', 'to assist with', 'preparations', 'ENT_POS')\n",
      "\t ('the accountancy firm PriceWaterhouseCoopers', 'for', 'a sale process', 'ENT_POS')\n",
      "\t ('preparations', 'for', 'a sale process', 'ENT_POS')\n",
      "Investment banks (NNS|nsubj) have (VBP|ROOT) yet (RB|advmod) to (TO|aux) be (VB|auxpass) formally (RB|advmod) appointed (VBN|xcomp) to (TO|aux) handle (VB|xcomp) an auction (NN|dobj) , (,|punct) and (CC|cc) one person (NN|nsubj) close (JJ|amod) to (IN|prep) the process (NN|pobj) said (VBD|conj) it (PRP|nsubj) was (VBD|ccomp) possible (JJ|acomp) that (IN|mark) Brookfield (NNP|nsubj) would (MD|aux) decide (VB|ccomp) to (TO|aux) retain (VB|xcomp) the business (NN|dobj) for (IN|prep) a longer period (NN|pobj) if (IN|mark) it (PRP|nsubj) did (VBD|aux) not (RB|neg) secure (VB|advcl) a sufficiently attractive offer (NN|dobj) . (.|punct)\n",
      "\t ('Investment banks', 'have yet to formally appointed to handle', 'one person', 'ENT_POS')\n",
      "\t ('Investment banks', 'close to', 'the process', 'ENT_POS')\n",
      "\t ('Investment banks', 'was possible', 'Brookfield', 'ENT_POS')\n",
      "\t ('Investment banks', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('an auction', 'close to', 'the process', 'ENT_POS')\n",
      "\t ('an auction', 'was possible', 'Brookfield', 'ENT_POS')\n",
      "\t ('an auction', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('one person', 'close to', 'the process', 'ENT_POS')\n",
      "\t ('one person', 'was possible', 'Brookfield', 'ENT_POS')\n",
      "\t ('one person', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('the process', 'was possible', 'Brookfield', 'ENT_POS')\n",
      "\t ('the process', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('it', 'was possible', 'Brookfield', 'ENT_POS')\n",
      "\t ('it', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('Brookfield', 'would decide to retain for', 'a longer period', 'ENT_POS')\n",
      "\t ('the business', 'for', 'a longer period', 'ENT_POS')\n",
      "Center Parcs (NNP|nsubj) is (VBZ|ROOT) one (CD|attr) of (IN|prep) the most famous brands (NNS|pobj) in (IN|prep) the British leisure industry (NN|pobj) , (,|punct) drawing (VBG|advcl) millions (NNS|dobj) of (IN|prep) visitors (NNS|pobj) annually (RB|advmod) to (IN|prep) its five UK sites (NNS|pobj) and (CC|cc) the (DT|det) latest (JJS|amod) addition (NN|conj) to (IN|prep) its portfolio (NN|pobj) , (,|punct) at (IN|prep) Longford Forest (NNP|pobj) in (IN|prep) Ireland (NNP|pobj) . (.|punct)\n",
      "\t ('Center Parcs', 'is of', 'the most famous brands', 'ENT_POS')\n",
      "\t ('Center Parcs', 'in', 'the British leisure industry', 'ENT_POS')\n",
      "\t ('Center Parcs', 'drawing of', 'visitors', 'ENT_POS')\n",
      "\t ('Center Parcs', 'annually to', 'its five UK sites', 'ENT_POS')\n",
      "\t ('Center Parcs', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('Center Parcs', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('Center Parcs', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('the most famous brands', 'in', 'the British leisure industry', 'ENT_POS')\n",
      "\t ('the most famous brands', 'drawing of', 'visitors', 'ENT_POS')\n",
      "\t ('the most famous brands', 'annually to', 'its five UK sites', 'ENT_POS')\n",
      "\t ('the most famous brands', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('the most famous brands', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('the most famous brands', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('the British leisure industry', 'drawing of', 'visitors', 'ENT_POS')\n",
      "\t ('the British leisure industry', 'annually to', 'its five UK sites', 'ENT_POS')\n",
      "\t ('the British leisure industry', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('the British leisure industry', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('the British leisure industry', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('millions', 'of', 'visitors', 'ENT_POS')\n",
      "\t ('millions', 'annually to', 'its five UK sites', 'ENT_POS')\n",
      "\t ('millions', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('millions', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('millions', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('visitors', 'annually to', 'its five UK sites', 'ENT_POS')\n",
      "\t ('visitors', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('visitors', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('visitors', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('its five UK sites', 'latest to', 'its portfolio', 'ENT_POS')\n",
      "\t ('its five UK sites', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('its five UK sites', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('its portfolio', 'at', 'Longford Forest', 'ENT_POS')\n",
      "\t ('its portfolio', 'in', 'Ireland', 'ENT_POS')\n",
      "\t ('Longford Forest', 'in', 'Ireland', 'ENT_POS')\n"
     ]
    }
   ],
   "source": [
    "for sent in list(doc.sents): \n",
    "    s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_})\" for t in sent])\n",
    "    entities, keys = get_entities(sent, noun_chunks=True)\n",
    "    \n",
    "    sentence_relations = get_ent_pos_relations(doc,entities)\n",
    "    if sentence_relations is not None:\n",
    "        relations+=sentence_relations\n",
    "\n",
    "        print(s_term_pos)\n",
    "        for r in sentence_relations:\n",
    "            print('\\t',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the relations in an \"edge list\" using e.g. an dataframe object or database table for further inspection and pruning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name1</th>\n",
       "      <th>relation</th>\n",
       "      <th>name2</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brookfield Property Partners</td>\n",
       "      <td>=IS</td>\n",
       "      <td>the Canadian property giant</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name1 relation                        name2  \\\n",
       "0  Brookfield Property Partners      =IS  the Canadian property giant   \n",
       "\n",
       "  relation_type  source_id  target_id  \n",
       "0        DIRECT          0          1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_relationships = pd.DataFrame(relations,columns=['name1','relation','name2','relation_type'])\n",
    "entity_map = {x:e for e,x in enumerate(pd.unique(entity_relationships[['name1','name2']].values.ravel()))}\n",
    "entity_relationships['source_id'] = entity_relationships['name1'].map(entity_map)\n",
    "entity_relationships['target_id'] = entity_relationships['name2'].map(entity_map)\n",
    "entity_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Knowledge Graph\n",
    "\n",
    "Now we are ready to build our knowledge graph. As the name implies a suitable structure to represent the data is in a [graph or complex network](https://en.wikipedia.org/wiki/Complex_network#Definition) data structure. Complex networks are suited to model non-trivial topological data structures and enable rich analysis of, among others, structural patterns, connectivity, cycles, hierarchy, shortest path, page rank, clustering, small world and randomness, etc. \n",
    "\n",
    "In mathematics, graph are commonly denoted $G(v,e)$ of $v$ vertices or nodes linked by $e$ edges. Our knowledge graph may then be $KG(e,r)$ of $e$ entities and noun chunks, and their relations $r$.\n",
    "\n",
    "In our case, it is important that we construct the knowledge graph using a directed graph. This is because the ordering and direction of the relationships we have extracted is important. For instance \"Center Park's\" is **IN** \"Ireland\" and not \n",
    "*vis versa*.\n",
    "\n",
    "There may be relationships types that do relate in each direction, or insights that can be gained by simply looking at entity connectivity and the number of relationships, or even link prediction. Complex networks, graph data structures, and graph analysis provide a wealth of options to analyse these data. \n",
    "\n",
    "> If you want to learn more about complex networks I recommend the websites, books, and learning materials of: [Prof Ernesto Estrada](https://sites.google.com/view/ernestoestrada/home), [Prof Albert Barabasi](https://www.barabasilab.com/), and [SNAP the Stanford Network Analysis Project](https://snap.stanford.edu/index.html).\n",
    "\n",
    "Now, we create a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import community\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create graph\n",
    "G=nx.DiGraph(name='simple KG')\n",
    "\n",
    "# add nodes\n",
    "for k,v in entity_map.items():\n",
    "    G.add_node(v,title=k,label=k, ent_typ='node') \n",
    "\n",
    "# add edges\n",
    "edges = [(row['source_id'],\n",
    "          row['target_id'],\n",
    "          {'weight':1, \n",
    "           'relation':row['relation'],\n",
    "           'title':row['relation']}) for ix,row in entity_relationships.iterrows()]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# add a size param\n",
    "sd = {k[0]:1+(k[1]**2) for k in G.degree}\n",
    "nx.set_node_attributes(G, sd, \"size\")\n",
    "\n",
    "# save\n",
    "joblib.dump(G,'graph.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Knowledge Graph of Entity Relationships\n",
    "\n",
    "One of the powerful applications of knowledge graph is search and information discovery. User interfaces and visualisations can be used to navigate the graph to discover patterns and relationships in the data.\n",
    "\n",
    "\n",
    "#### Networkx\n",
    "\n",
    "First, there is [Networkx](https://networkx.org/documentation/stable/reference/drawing.html?highlight=layout#) for quick graph analytics and visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlotGraph:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def node_partition_color(self,graph):\n",
    "        \"\"\"\n",
    "        compute the node partitions for colouring\n",
    "        \"\"\"\n",
    "\n",
    "        if graph.is_directed():\n",
    "            # for directed graphs\n",
    "            c = list(greedy_modularity_communities(graph))\n",
    "            node_color=dict()\n",
    "            for e,s in enumerate(c):\n",
    "                for n in s:\n",
    "                    node_color[n] = e\n",
    "            node_color = [node_color[k] for k in sorted(node_color.keys())]\n",
    "\n",
    "        else:\n",
    "            # for un-directed graphs\n",
    "            partition = community.best_partition(graph)\n",
    "            node_color= partition\n",
    "\n",
    "        return node_color\n",
    "    \n",
    "    def plot_graph(self,axis,graph):\n",
    "        node_size = [15+(v**3) for k,v in graph.degree]\n",
    "        node_labels = {node[0]:node[1]['title'] for node in graph.nodes(data=True)}\n",
    "        edge_labels = {(i[0],i[1]):i[2]['relation'] for i in graph.edges(data=True)}\n",
    "        pos = nx.layout.spring_layout(graph,iterations=300,k=4)\n",
    "        \n",
    "        nx.draw(graph,pos=pos,\n",
    "                ax=axis,\n",
    "                node_color=self.node_partition_color(graph),\n",
    "                node_size=node_size,\n",
    "                labels=node_labels,\n",
    "                width=0.9)\n",
    "        \n",
    "        nx.draw_networkx_edge_labels(graph,pos,\n",
    "                                     ax=axis,\n",
    "                                     edge_labels=edge_labels,\n",
    "                                     font_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "fig,axs = plt.subplots(1,1, figsize=(15,15))\n",
    "pg = PlotGraph()\n",
    "pg.plot_graph(axs,G)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added a function to colour the node's within the tightly connected \"modular\" portions of the network. When plotting the entire graph this highlights some distinct connected components and subgraphs of the overall knowledge graph. I.e. there are some entities and nodes that are not connected to one another at all. \n",
    "\n",
    "This is not surprising given the nature of the input data. Now, some of the content and entities in this data are for \"Sky News\" and about the expansion of \"Center Park's\".\n",
    "\n",
    "I could go an retrieve some more text about these entities, process them for relations, and add them to the graph. Would that be helpful? Possibly. But it would also create and relations from the new texts and that might be on new topics such as covid booking numbers or the appointment of a new CEO. Anything. The point is, when constructing the knowledge graph it is important to consider what data you want to model otherwise you might end up with a web of spaghetti.\n",
    "\n",
    "Below, I split the graphs by connected component and re-plot. Note that I converted the DirectedGraph to an un-directed Graph to calculate the components as I'm just interested in any relationship at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uG = G.to_undirected()\n",
    "sg = [G.subgraph(c) for c in nx.connected_components(uG)]\n",
    "ng = len(sg)\n",
    "\n",
    "# plot graph\n",
    "fig,axs = plt.subplots(ng,1, figsize=(9,ng*9))\n",
    "pg = PlotGraph()\n",
    "for ax,g in zip(axs.flatten(),sg):\n",
    "    pg.plot_graph(ax,g)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [PyVis](https://pyvis.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "\n",
    "PyVis provides interactive physics and in-line notebook network plotting. Unfortunately, it seems some customisation of the css would be required to display the edge names in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "net = Network(notebook=True,directed=True,height=\"700px\",width=\"100%\")\n",
    "net.from_nx(sg[1])\n",
    "net.show_buttons(filter_=['physics'])\n",
    "net.show('graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streamlit\n",
    "\n",
    "Lastly, there is the [Streamlit Agraph component](https://github.com/ChrisDelClea/streamlit-agraph).\n",
    "\n",
    "<img src=\"./streamlit.png\" width=600 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "## References\n",
    " - [information-extraction-with-dominating-rules](https://github.com/philipperemy/information-extraction-with-dominating-rules)\n",
    " - [Pruning Knowledge Graphs](http://philipperemy.github.io/information-extract/)\n",
    "\n",
    " - [Knowledge Graph â A Powerful Data Science Technique to Mine Information from Text](https://www.analyticsvidhya.com/blog/2019/10/how-to-build-knowledge-graph-text-using-spacy/)\n",
    " - [Spacy subject-object extraction](https://github.com/NSchrading/intro-spacy-nlp/blob/master/subject_object_extraction.py)\n",
    "     -  [subject-object dependency parsing](https://stackoverflow.com/questions/39763091/how-to-extract-subjects-in-a-sentence-and-their-respective-dependent-phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
