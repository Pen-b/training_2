{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b9c1dde0b2464ff6778d75d84efd3ba2ef21848"
   },
   "source": [
    "# Rule Based Relation-Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "85600930b325b2bc99c604b7535cf298e475c247"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  [\n",
    "    # https://www.bbc.co.uk/news/world-us-canada-60177979\n",
    "    (\n",
    "        \"The US East Coast is hunkering down as a major blizzard hits the region for the first time in four years.\"\n",
    "        \"The storm is forecast to stretch from the Carolinas to Maine, packing hurricane-force winds in coastal parts.\"\n",
    "        \"Five states have declared emergencies.\"\n",
    "        \"Mayor Michelle Wu of Boston, a city that is no stranger to snowfall, said the storm could be 'historic'.\"\n",
    "        \"More than two feet of snow could fall in New England.\"\n",
    "        \"Weather officials also warn of flooding near the coast.\"\n",
    "        \"Over 5,000 US flights were cancelled between Friday and Sunday, according to FlightAware.\"\n",
    "        \"Forecasters say there is a chance the storm, known as a Nor\\'easter, will blanket the Boston area with up to 2ft (61cm) of snow.\"\n",
    "        ),\n",
    "    # https://www.bbc.co.uk/news/business-60163814\n",
    "    (  \n",
    "        \"Apple sales soared in the key Christmas shopping season, despite constraints due to a global shortage of microchips.\"\n",
    "        \"Sales at the iPhone giant rose 11% to a record $123.9bn (Â£92.6bn) in the October to December period, beating forecasts.\"\n",
    "        \"Shares jumped more than 4% in after-hours trade, as the report suggested the firm's pandemic boom is continuing.\"\n",
    "        \"Apple has seen purchases skyrocket during the pandemic as people spend more time online.\"\n",
    "        \"The firm's market value briefly hit the $3tn milestone in early January though its share price has slipped more recently amid weeks of market turmoil.\"\n",
    "        ),\n",
    "    # https://news.sky.com/story/staycation-frenzy-spurs-center-parcs-owner-to-prepare-4bn-sale-12527982\n",
    "    (\n",
    "        \"Sky News has learnt that Brookfield Property Partners, the Canadian property giant, is paving the way to sell Center Parcs UK potentially as soon as this year.\"\n",
    "        \"City sources said this weekend that Brookfield had engaged the accountancy firm PriceWaterhouseCoopers to assist with preparations for a sale process.\"\n",
    "        \"Investment banks have yet to be formally appointed to handle an auction, and one person close to the process said it was possible that Brookfield would decide to retain the business for a longer period if it did not secure a sufficiently attractive offer.\"\n",
    "        \"Center Parcs is one of the most famous brands in the British leisure industry, drawing millions of visitors annually to its five UK sites and the latest addition to its portfolio, at Longford Forest in Ireland.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2099872afd539fa28784a066f2ce0c06c42a2585"
   },
   "source": [
    "##  Part-Of-Speech (POS) tags\n",
    "\n",
    "In linguistics and grammar, A part of speech or part-of-speech (POS) is the category of a word that have similar grammatical properties. \n",
    "For instance \"nouns\" are words for real things like people, places and objects. Words that describe nouns are called \"adjectives\" such as: tall, smart, large. \n",
    "\n",
    "Applications in Natural Language Processing (NLP) apply linguistic rules and machine learning models to predict and assign which POS tags apply by evaluating word position and context. Popular NLP packages such as NLTK and spaCy include this functionality OOTB. To read more about POS, see this [POS summary](https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba), the spaCy [documentation](https://spacy.io/usage/linguistic-features#pos-tagging) and [SO explanation](https://stackoverflow.com/questions/40288323/what-do-spacys-part-of-speech-and-dependency-tags-mean), and this [POS tag reference list](https://sites.google.com/site/partofspeechhelp/#TOC-Welcome).\n",
    "\n",
    "We can build a basic relation-extraction process by using grammar patterns / part of speech patterns to identify related nouns within a text. A simple rule might be:\n",
    "\n",
    "```\n",
    "Proper Noun - Verb - Proper Noun\n",
    "```\n",
    "\n",
    "Using spaCy, we can now iterate over each sentence and identify where this POS pattern occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "fd80efd1e651449ee42847f5859feadea27a15ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[US, hunkering, blizzard] \n",
      " US (NNP|compound) East (NNP|compound) Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      "\n",
      "[East, hunkering, blizzard] \n",
      " East (NNP|compound) Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      "\n",
      "[Coast, hunkering, blizzard] \n",
      " Coast (NNP|nsubj) is (VBZ|aux) hunkering (VBG|ROOT) down (RP|prt) as (IN|mark) a (DT|det) major (JJ|amod) blizzard (NN|nsubj) \n",
      "\n",
      "[Apple, soared, Christmas] \n",
      " Apple (NN|compound) sales (NNS|nsubj) soared (VBD|ROOT) in (IN|prep) the (DT|det) key (JJ|amod) Christmas (NNP|compound) \n",
      "\n",
      "[sales, soared, Christmas] \n",
      " sales (NNS|nsubj) soared (VBD|ROOT) in (IN|prep) the (DT|det) key (JJ|amod) Christmas (NNP|compound) \n",
      "\n",
      "[Sky, learnt, Brookfield] \n",
      " Sky (NNP|compound) News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield (NNP|compound) \n",
      "\n",
      "[News, learnt, Brookfield] \n",
      " News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield (NNP|compound) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns = ['NNP','NN','NNS']\n",
    "verbs = [\"VBZ\",\"VB\",\"VBG\"]\n",
    "relations = list()\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    for e,sent in enumerate(doc.sents):\n",
    "        chain = list()\n",
    "        for a in sent:\n",
    "            if a.tag_ in nouns: # find first NOUND\n",
    "                chain.append(a)\n",
    "                for b in sent[a.i:]: # find ROOT, alternatively VERBS\n",
    "                    if (b.dep_ == 'ROOT') and len(chain) == 1:\n",
    "                        chain.append(b)\n",
    "                        for c in sent[b.i:]: # find second NOUN\n",
    "                            if c.tag_ in nouns and len(chain) == 2: \n",
    "                                chain.append(c)\n",
    "                                \n",
    "                                # reset chain and print result\n",
    "                                relations.append(chain)\n",
    "                                pos_chain = ' '.join([f\"{i} ({i.tag_}|{i.dep_})\" for i in sent[a.i:c.i+1]])\n",
    "                                print(chain,'\\n',pos_chain,'\\n')\n",
    "                                chain = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this simple approach seems OK at finding sentences that contain related entities.\n",
    "\n",
    "- US --- **hunkering** ---> Blizzard\n",
    "- Sales --- **soared** ---> Christmas\n",
    "- Sky --- **learnt** ---> Brookfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction\n",
    "\n",
    "The problem with the above approach is that it relies on an extensive list of *Part-Of-Speech* tag patterns. This won't scale for most problems as nouns and verbs come in a wide variety of forms and with modifiers etc. For instance, you generally want to capture compound term phrases and patterns such as:\n",
    "```\n",
    "Metro-North worker = NNP-HYPH-NNP\n",
    "Killed by = VBZ-IN\n",
    "```\n",
    "\n",
    "To improve our method we can:\n",
    " 1. Better capture and relfect things and objects - collectively named \"entities\".\n",
    "     \n",
    " \n",
    " 1. Develop POS patterns and rules to identify and extract relations between two or more entities. \n",
    "\n",
    " 1. Train a probabilistic model to identify relation triplets such as [Stanford, OLLIE - see reddit]\n",
    " \n",
    "### Capture entities\n",
    "\n",
    "A spacy pipeline with components for Named Entity Recognition (NER) and Noun Chunks is used to capture entities. Here, we could define some sensible rules or limit the number and type of entities to control what information will be represented in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'merge_entities', 'merge_noun_chunks']\n",
      "\n",
      " Sky News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield Property Partners (NNPS|nsubj) , (,|punct) the Canadian property giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the way (NN|dobj) to (TO|aux) sell (VB|relcl) Center Parcs UK (NNP|dobj) potentially (RB|advmod) as (RB|advmod) soon (RB|advmod) as (IN|prep) this year (NN|pobj) . (.|punct) City sources (NNS|nsubj) said (VBD|ROOT) this weekend (NN|npadvmod) that (IN|mark) Brookfield (NNP|nsubj) had (VBD|aux) engaged (VBN|ccomp) the accountancy firm PriceWaterhouseCoopers (NNS|dobj) to (TO|aux) assist (VB|xcomp) with (IN|prep) preparations (NNS|pobj) for (IN|prep) a sale process (NN|pobj) . (.|punct) Investment banks (NNS|nsubj) have (VBP|ROOT) yet (RB|advmod) to (TO|aux) be (VB|auxpass) formally (RB|advmod) appointed (VBN|xcomp) to (TO|aux) handle (VB|xcomp) an auction (NN|dobj) , (,|punct) and (CC|cc) one person (NN|nsubj) close (JJ|amod) to (IN|prep) the process (NN|pobj) said (VBD|conj) it (PRP|nsubj) was (VBD|ccomp) possible (JJ|acomp) that (IN|mark) Brookfield (NNP|nsubj) would (MD|aux) decide (VB|ccomp) to (TO|aux) retain (VB|xcomp) the business (NN|dobj) for (IN|prep) a longer period (NN|pobj) if (IN|mark) it (PRP|nsubj) did (VBD|aux) not (RB|neg) secure (VB|advcl) a sufficiently attractive offer (NN|dobj) . (.|punct) Center Parcs (NNP|nsubj) is (VBZ|ROOT) one (CD|attr) of (IN|prep) the most famous brands (NNS|pobj) in (IN|prep) the British leisure industry (NN|pobj) , (,|punct) drawing (VBG|advcl) millions (NNS|dobj) of (IN|prep) visitors (NNS|pobj) annually (RB|advmod) to (IN|prep) its five UK sites (NNS|pobj) and (CC|cc) the (DT|det) latest (JJS|amod) addition (NN|conj) to (IN|prep) its portfolio (NN|pobj) , (,|punct) at (IN|prep) Longford Forest (NNP|pobj) in (IN|prep) Ireland (NNP|pobj) . (.|punct) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sky News\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has learnt that \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield Property Partners\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", the Canadian property giant, is paving the way to sell \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Center Parcs UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " potentially as soon as \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".City sources said \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    this weekend\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " had engaged the accountancy firm PriceWaterhouseCoopers to assist with preparations for a sale process.Investment banks have yet to be formally appointed to handle an auction, and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one person\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " close to the process said it was possible that \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brookfield\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " would decide to retain the business for a longer period if it did not secure a sufficiently attractive offer.\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Center Parcs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the most famous brands in the British leisure industry, drawing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    millions\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of visitors \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    annually\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to its five UK sites and the latest addition to its portfolio, at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Longford Forest\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ireland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "\t Sky News ORG\n",
      "\t Brookfield Property Partners ORG\n",
      "\t Center Parcs UK ORG\n",
      "\t this year DATE\n",
      "\t this weekend DATE\n",
      "\t Brookfield GPE\n",
      "\t one person CARDINAL\n",
      "\t Brookfield GPE\n",
      "\t Center Parcs ORG\n",
      "\t one CARDINAL\n",
      "\t millions CARDINAL\n",
      "\t annually DATE\n",
      "\t Longford Forest ORG\n",
      "\t Ireland GPE\n",
      "Noun chunks:\n",
      "\t Sky News\n",
      "\t Brookfield Property Partners\n",
      "\t the Canadian property giant\n",
      "\t the way\n",
      "\t Center Parcs UK\n",
      "\t this year\n",
      "\t City sources\n",
      "\t Brookfield\n",
      "\t the accountancy firm PriceWaterhouseCoopers\n",
      "\t preparations\n",
      "\t a sale process\n",
      "\t Investment banks\n",
      "\t an auction\n",
      "\t one person\n",
      "\t the process\n",
      "\t it\n",
      "\t Brookfield\n",
      "\t the business\n",
      "\t a longer period\n",
      "\t it\n",
      "\t a sufficiently attractive offer\n",
      "\t Center Parcs\n",
      "\t the most famous brands\n",
      "\t the British leisure industry\n",
      "\t millions\n",
      "\t visitors\n",
      "\t its five UK sites\n",
      "\t its portfolio\n",
      "\t Longford Forest\n",
      "\t Ireland\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_noun_chunks\"))\n",
    "    print(nlp.pipe_names)\n",
    "except:\n",
    "    print(nlp.pipe_names)\n",
    "\n",
    "\n",
    "doc = nlp(texts[2])\n",
    "print('\\n', ' '.join([f\"{d} ({d.tag_}|{d.dep_})\" for d in doc]),'\\n')\n",
    "spacy.displacy.render(doc, style='ent')\n",
    "\n",
    "print('Entities:')\n",
    "for t in doc:\n",
    "    if t.ent_type_ != '': print('\\t',t,t.ent_type_)\n",
    "\n",
    "print('Noun chunks:')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('\\t',chunk.text, )\n",
    "    #chunk.root.text, chunk.root.dep_,chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture relations\n",
    "\n",
    "For each sentence, relations can be extracted by iterating through the entity pairs and noun chunks, and yielding the VERB dependency or ROOT tag terms. Spacy's dependency parser operates on each sentence in isolation and so it is not possible to extract relations across sentences with this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(span,ent_types=None,noun_chunks=False):\n",
    "    entities = dict()\n",
    "    if ent_types is None:\n",
    "        ent_types = ['ORG','PERSON','GPE','NORP','LOC','PRODUCT']\n",
    "        \n",
    "    if noun_chunks:\n",
    "        entities.update({int(f\"{i.start}{i.end}\"): {\"span\":i, \"type\":\"NOUN_CHUNK\"} for i in span.noun_chunks})\n",
    "        \n",
    "    entities.update({int(f\"{i.start}{i.end}\"): {\"span\":i, \"type\":i.label_} for i in span.ents if i.label_ in ent_types})\n",
    "    keys = sorted(entities)\n",
    "    return entities, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sky News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield Property Partners (NNPS|nsubj) , (,|punct) the Canadian property giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the way (NN|dobj) to (TO|aux) sell (VB|relcl) Center Parcs UK (NNP|dobj) potentially (RB|advmod) as (RB|advmod) soon (RB|advmod) as (IN|prep) this year (NN|pobj) . (.|punct)\n",
      "\t>>>\t Sky News - has(VBZ|aux) - Brookfield Property Partners\n",
      "\t>>>\t Sky News - learnt(VBN|ROOT) - Brookfield Property Partners\n",
      "\t>>>\t Brookfield Property Partners - is(VBZ|aux) - Center Parcs UK\n",
      "\t>>>\t Brookfield Property Partners - paving(VBG|ccomp) - Center Parcs UK\n",
      "\t>>>\t Brookfield Property Partners - sell(VB|relcl) - Center Parcs UK\n",
      "\n",
      " Center Parcs (NNP|nsubj) is (VBZ|ROOT) one (CD|attr) of (IN|prep) the most famous brands (NNS|pobj) in (IN|prep) the British leisure industry (NN|pobj) , (,|punct) drawing (VBG|advcl) millions (NNS|dobj) of (IN|prep) visitors (NNS|pobj) annually (RB|advmod) to (IN|prep) its five UK sites (NNS|pobj) and (CC|cc) the (DT|det) latest (JJS|amod) addition (NN|conj) to (IN|prep) its portfolio (NN|pobj) , (,|punct) at (IN|prep) Longford Forest (NNP|pobj) in (IN|prep) Ireland (NNP|pobj) . (.|punct)\n",
      "\t>>>\t Center Parcs - is(VBZ|ROOT) - Longford Forest\n",
      "\t>>>\t Center Parcs - drawing(VBG|advcl) - Longford Forest\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents: \n",
    "    s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_})\" for t in sent])\n",
    "    entities, keys = get_entities(sent)\n",
    "\n",
    "    if len(keys) > 1:\n",
    "        pairs = [(x,y) for x,y in zip(keys,keys[1:])]\n",
    "        print('\\n',s_term_pos)\n",
    "        # print(keys,pairs)\n",
    "        for p in pairs:\n",
    "            start,end = entities[p[0]], entities[p[1]]\n",
    "            for w in doc[start['span'].start:end['span'].end]:\n",
    "                if w.tag_ in ['VBZ','VBN','VBG','VBD','VB']:\n",
    "                    print(f\"\\t>>>\\t\",f\"{start['span']} - {w}({w.tag_}|{w.dep_}) - {end['span']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.displacy.render(doc, style='ent')\n",
    "# spacy.displacy.render(sent, style='dep',)\n",
    "# spacy.explain('attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better - but not great. \n",
    "\n",
    "There's a few additional rules we could add to expand and improve the capture. \n",
    "\n",
    "- capture direct ascendants and decedents https://spacy.io/usage/linguistic-features#navigating-around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relation(subj='ben', rel='is', obj='here', type='DIRECT')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/47784683\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(eq=True)\n",
    "class Relation:\n",
    "    subj: str\n",
    "    rel: str\n",
    "    obj: str\n",
    "    type: str\n",
    "Relation('ben','is','here','DIRECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sky News (NNP|nsubj) has (VBZ|aux) learnt (VBN|ROOT) that (IN|mark) Brookfield Property Partners (NNPS|nsubj) , (,|punct) the Canadian property giant (NN|appos) , (,|punct) is (VBZ|aux) paving (VBG|ccomp) the way (NN|dobj) to (TO|aux) sell (VB|relcl) Center Parcs UK (NNP|dobj) potentially (RB|advmod) as (RB|advmod) soon (RB|advmod) as (IN|prep) this year (NN|pobj) . (.|punct)\n",
      "\t ('Brookfield Property Partners', '=IS', the Canadian property giant, 'DIRECT')\n"
     ]
    }
   ],
   "source": [
    "def get_direct_relations(sent,entities):\n",
    "    ent_text = [v['span'].text for v in entities.values()]\n",
    "    relations = list()\n",
    "\n",
    "    for v in entities.values():\n",
    "        \n",
    "        if v['span'].n_lefts > 0:\n",
    "            lf = [i for i in v['span'].lefts if i.text in ent_text]\n",
    "            if len(lf) > 0: \n",
    "                relations.append((lf[0],'=IS',v,'DIRECT'))\n",
    "        if v['span'].n_rights > 0:\n",
    "            rt = [i for i in v['span'].rights if i.text in ent_text]\n",
    "            if len(rt) > 0: \n",
    "                relations.append((v['span'].text,'=IS',rt[0],'DIRECT'))\n",
    "\n",
    "    if len(relations) > 0:\n",
    "        return relations\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "relations = list()\n",
    "\n",
    "for sent in list(doc.sents)[:]: \n",
    "    s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_})\" for t in sent])\n",
    "    entities, keys = get_entities(sent, noun_chunks=True)\n",
    "    \n",
    "    sentence_relations = get_direct_relations(sent,entities)\n",
    "    if sentence_relations is not None:\n",
    "        relations+=sentence_relations\n",
    "        \n",
    "        print(s_term_pos)\n",
    "        for r in sentence_relations:\n",
    "            print('\\t',r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brookfield Property Partners', '=IS', the Canadian property giant)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_relations(doc, sentence_entities):\n",
    "    SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "    OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
    "    SUB_OBJ = SUBJECTS+OBJECTS\n",
    "    \n",
    "    feature = [  \"ROOT\",\n",
    "                 \"aux\",\n",
    "                 \"acomp\", \"advcl\", \"advmod\", \"amod\", \"appos\", \"nn\", \"nmod\", \"ccomp\", \"complm\",\n",
    "                 \"hmod\", \"infmod\", \"xcomp\", \"rcmod\", \"poss\",\" possessive\",\n",
    "                 \"compound\",\n",
    "                 \"prep\"]\n",
    "\n",
    "    for e in sentence_entities.values():\n",
    "        prev = list()\n",
    "        for t in doc[e['span'].end:sent.end]:\n",
    "            if t.dep_ =='pobj': \n",
    "                terms = doc[e['span'].end:t.i]\n",
    "                rels = [t for t in terms if t.dep_ in feature if t.idx not in prev]\n",
    "                prev.extend([x.idx for x in rels]) # previous terms\n",
    "                rels = ' '.join([x.text for x in rels])\n",
    "\n",
    "                print('\\t',e['span'],f'-{rels}-',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in list(doc.sents)[:]: \n",
    "    s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_})\" for t in sent])\n",
    "    entities, keys = get_entities(sent, noun_chunks=True)\n",
    "    \n",
    "    print(s_term_pos, [i['span'] for i in entities.values()])\n",
    "    get_pos_relations(doc,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_relations(start,end):\n",
    "    relations = list()\n",
    "    for word in doc[start['span'].start:end['span'].end]:\n",
    "        if word.tag_ in ['VB','VBN', 'VBZ']: # 'VBZ','VBG','VBD',\n",
    "            \n",
    "            left = list(word.lefts)\n",
    "            left = [i for i in left if len(left) > 0 and i.i > start['span'].end-1]\n",
    "            \n",
    "            right = list(word.rights)\n",
    "            right = [i for i in right if len(right) > 0 and i.i < end['span'].start]\n",
    "            \n",
    "            verb = ' '.join([l.text for l in left] + [word.text] + [r.text for r in right])\n",
    "            relations.append((start['span'],verb,end['span']))\n",
    "    if len(relations) > 0:\n",
    "        return relations\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in list(doc.sents): \n",
    "    sentence_relations = list()\n",
    "    s_term_pos = \" \".join([f\"{t} ({t.tag_}|{t.dep_})\" for t in sent])\n",
    "    \n",
    "    entities, keys = get_entities(sent,noun_chunks=True)\n",
    "    relations = get_direct_relations(sent,entities)\n",
    "    \n",
    "    if len(relations) > 0:\n",
    "        sentence_relations += relations\n",
    "    \n",
    "    entities, keys = get_entities(sent,noun_chunks=True)\n",
    "    if len(keys) > 1:\n",
    "        pairs = [(x,y) for x,y in zip(keys,keys[1:])]\n",
    "        for p in pairs:\n",
    "            start,end = entities[p[0]], entities[p[1]]\n",
    "            relations = get_verb_relations(start,end)\n",
    "            if relations is not None:\n",
    "                sentence_relations += relations\n",
    "                \n",
    "            \n",
    "    print('\\n',s_term_pos)\n",
    "    for r in sentence_relations:\n",
    "        print(f\"\\t{r}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so using NE appears better able to capture our people and organisations. However, naievely creating Triplets by extracting the verbs between Entities is not that good due to:\n",
    " - It fails on complex sentence structures. \n",
    " - It ignores other objects represented by Nouns, Propper Nouns, and Common Nouns etc. \n",
    " - Not all ENTITY types are relevant: PERSON:ORDINAL\n",
    "\n",
    "We could improve some of this by incoporating **[Noun Chunks](https://spacy.io/usage/linguistic-features#noun-chunks)**. You can think of noun chunks as a noun plus the words describing the noun â for example, âthe lavish green grassâ or âthe worldâs largest tech fundâ.\n",
    "\n",
    "    Text: The original noun chunk text.\n",
    "    Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "    Root dep: Dependency relation connecting the root to its head.\n",
    "    Root head text: The text of the root tokenâs head.\n",
    "    Children: The immediate syntactic dependents of the root token.\n",
    "    \n",
    " - spaCy uses the terms **head** and **child** to describe the words connected by a single arc in the dependency tree. \n",
    " - The term **dep** is used for the arc label, which describes the type of syntactic relation that connects the child to the head.\n",
    " \n",
    "We can extract further relations by examining the noun modifiers in the noun chunks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other factors to consider:\n",
    "\n",
    " - Ownership: E.g. Noun or Named Entity followed by : [NNS/VBZ](https://sites.google.com/site/partofspeechhelp/home/nns_vbz)\n",
    " - [KG and pruning](http://philipperemy.github.io/information-extract/)\n",
    "  - [git](https://github.com/philipperemy/information-extraction-with-dominating-rules)\n",
    " \n",
    "## References\n",
    "\n",
    " - [OLLIE](https://www.reddit.com/r/LanguageTechnology/comments/bovsf5/we_release_opiec_the_largest_open_information/)\n",
    " - [Clausie](https://github.com/mmxgn/clausiepy)\n",
    " - [Minie](https://github.com/mmxgn/miniepy/graphs/contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(findSVAOs(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
