{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b9c1dde0b2464ff6778d75d84efd3ba2ef21848"
   },
   "source": [
    "# Rule Based Relation-Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "85600930b325b2bc99c604b7535cf298e475c247"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "\n",
    "# Load the en_core_web_sm model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacy_title</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Fed, official, says, weak, data, caused, by, ...</td>\n",
       "      <td>((Fed),)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Fed, 's, Charles, Plosser, sees, high, bar, f...</td>\n",
       "      <td>((Fed), (Charles, Plosser))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(US, open, :, Stocks, fall, after, Fed, offici...</td>\n",
       "      <td>((US), (Fed))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         spacy_title  \\\n",
       "0  (Fed, official, says, weak, data, caused, by, ...   \n",
       "1  (Fed, 's, Charles, Plosser, sees, high, bar, f...   \n",
       "2  (US, open, :, Stocks, fall, after, Fed, offici...   \n",
       "\n",
       "                named_entities  \n",
       "0                     ((Fed),)  \n",
       "1  ((Fed), (Charles, Plosser))  \n",
       "2                ((US), (Fed))  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/uci-news-aggregator\"\n",
    "files = os.listdir(path)\n",
    "df = pd.read_csv(os.path.join(path,files[1]),nrows=500)\n",
    "\n",
    "\n",
    "# Apply spacy to the article titles\n",
    "df[\"spacy_title\"] = df[\"TITLE\"].apply(lambda x : nlp(x))\n",
    "\n",
    "# add field of NE\n",
    "df[\"named_entities\"] = df[\"spacy_title\"].apply(lambda x : x.ents)\n",
    "\n",
    "df[['spacy_title','named_entities']][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2099872afd539fa28784a066f2ce0c06c42a2585"
   },
   "source": [
    "##  Part-Of-Speech (POS) tags\n",
    "\n",
    "In linguistics and grammar, A part of speech or part-of-speech (POS) is the category of a word that have similar grammatical properties. \n",
    "For instance \"nouns\" are words for real things like people, places and objects. Words that describe nouns are called \"adjectives\" such as: tall, smart, large. \n",
    "\n",
    "Applications in Natural Language Processing (NLP) apply linguistic rules and machine learning models to predict and assign which POS tags apply by evaluating word position and context. Popular NLP packages such as NLTK and spaCy include this functionality OOTB. To read more about POS, see this [POS summary](https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba), the spaCy [documentation](https://spacy.io/usage/linguistic-features#pos-tagging) and [SO explanation](https://stackoverflow.com/questions/40288323/what-do-spacys-part-of-speech-and-dependency-tags-mean), and this [POS tag reference list](https://sites.google.com/site/partofspeechhelp/#TOC-Welcome).\n",
    "\n",
    "We can build a basic relation-extraction process by using grammar patterns / part of speech patterns to identify related nouns within a text. A simple rule might be:\n",
    "\n",
    "```\n",
    "Proper Noun - Verb - Proper Noun\n",
    "```\n",
    "\n",
    "Using spaCy, we can now iterate over each sentence and identify where this POS pattern occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "fd80efd1e651449ee42847f5859feadea27a15ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\tEBay rejects Icahn slate of directors\n",
      "\tNNP-VBZ-NNP-NN-IN-NNS\n",
      "\n",
      "55\tIcahn Targets Ebay Chief Donahoe After Company Rejects Board Slate\n",
      "\tNNP-NNP-NNP-NNP-NNP-IN-NNP-VBZ-NNP-NNP\n",
      "\n",
      "66\teBay's John Donahoe talks Icahn, conflicts, and $100 stock price (someday)\n",
      "\tNNP-POS-NNP-NNP-VBZ-NNP-,-NNS-,-CC-$-CD-NN-NN--LRB--RB--RRB-\n",
      "\n",
      "20\tNoyer Says Strong Euro Creates Unwarranted Economic Pressure (1)\n",
      "\tNNP-VBZ-NNP-NNP-VBZ-JJ-NNP-NN--LRB--CD--RRB-\n",
      "\n",
      "68\tCarl Icahn slams eBay CEO\n",
      "\tNNP-NNP-VBZ-NNP-NNP\n",
      "\n",
      "320\tJapan says Bitcoin's not currency, but taxable\n",
      "\tNNP-VBZ-NNP-POS-RB-NN-,-CC-JJ\n",
      "\n",
      "7\tFed's Plosser expects US unemployment to fall to 6.2% by the end of 2014\n",
      "\tNNP-POS-NNP-VBZ-NNP-NN-TO-VB-IN-CD-NN-IN-DT-NN-IN-CD\n",
      "\n",
      "368\tWeil on Finance: Bill Ackman Keeps Hope Alive\n",
      "\tNNP-IN-NNP-:-NNP-NNP-VBZ-NNP-NNP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_pattern = \"NNP-VBZ-NNP\"\n",
    "\n",
    "counter = 0\n",
    "limit = 8\n",
    "index_list = list()\n",
    "\n",
    "for i, r in df.sample(frac=0.7).iterrows():\n",
    "    pos_chain = \"-\".join([d.tag_ for d in r['spacy_title']])\n",
    "    if pos_pattern in pos_chain:\n",
    "        if len(r[\"named_entities\"]) >= 2:\n",
    "            index_list.append(i)\n",
    "            print (f\"{i}\\t{r.TITLE}\\n\\t{pos_chain}\\n\",)\n",
    "            \n",
    "            counter+=1\n",
    "            if counter==limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples to pull out patterns\n",
    "\n",
    "# doc = nlp(df.loc[7,'TITLE'])\n",
    "# pos_chain = \"-\".join([d.tag_ for d in doc])\n",
    "# doc,pos_chain,pos_pattern \n",
    "\n",
    "# import re\n",
    "  \n",
    "# # Find start end\n",
    "# def substr_index(string,pattern):\n",
    "#     a = [(m.start(),m.end()) for m in re.finditer('{0}'.format(pattern), string)]\n",
    "#     return a\n",
    "\n",
    "# substr_index(pos_chain,pos_pattern)\n",
    "# [(t.i,t,t.tag_ ) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this simple approach seems OK at finding sentences with related entities and thei relationships.\n",
    "\n",
    "- Honda --- **restructures** ---> US operations  \n",
    "- Carl Icahn --- **slams** ---> eBay CEO\n",
    "- Google --- **confirms** ---> Android SDK \n",
    "- GM --- **hires** ---> Lehman Brothers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS patterns\n",
    "\n",
    "The problem with the above approach is that it relies on an extensive list of *Part-Of-Speech* tag patterns. This won't scale for most problems as nouns and verbs come in a wide variety of forms and with modifiers etc. For instance, you generally want to capture compound term phrases and patterns such as:\n",
    "```\n",
    "Metro-North worker = NNP-HYPH-NNP\n",
    "Killed by = VBZ-IN\n",
    "```\n",
    "\n",
    "To improve our method we can:\n",
    " 1. Use Named Entity Recognition and Noun Chunks to better capture things and objects.\n",
    "     - Also, we can define sensible rules to limit the type of entities on which to find relations between.\n",
    " \n",
    " 1. Constrain the type and number of relations you wish to find, create patterns for those. \n",
    "\n",
    " 1. Train a probabilistic model to identify relation triplets such as [Stanford, OLLIE - see reddit]\n",
    " \n",
    "Below we will try to form relations using approach 2, between named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'merge_entities', 'merge_noun_chunks']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_noun_chunks\"))\n",
    "    print(nlp.pipe_names)\n",
    "except:\n",
    "    print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben Postance (NNP|nsubj) lives (VBZ|ROOT) in (IN|prep) Birmingham (NNP|pobj) . (.|punct) Ben (NNP|nsubj) is (VBZ|ROOT) about 30 years old (JJ|acomp) . (.|punct) Fed's Plosser (NNP|nsubj) expects (VBZ|ROOT) United States (NNP|nsubj) unemployment (NN|nsubj) to (TO|aux) fall (VB|ccomp) to (IN|prep) 6.2% (NN|pobj) by (IN|prep) the end of 2014 (NN|pobj) . (.|punct) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ben Postance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Birmingham\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Ben\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 30 years old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Fed's Plosser\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " expects \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " unemployment to fall to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    6.2%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " by \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the end of 2014\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Ben Postance lives in Birmingham. Ben is about 30 years old. Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\"\n",
    "doc = nlp(text)\n",
    "print(' '.join([f\"{d} ({d.tag_}|{d.dep_})\" for d in doc]),'\\n')\n",
    "spacy.displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "\t Ben Postance PERSON\n",
      "\t Birmingham GPE\n",
      "\t Ben PERSON\n",
      "\t about 30 years old DATE\n",
      "\t Fed's Plosser ORG\n",
      "\t United States GPE\n",
      "\t 6.2% PERCENT\n",
      "\t the end of 2014 DATE\n",
      "Noun chunks:\n",
      "\t Ben Postance\n",
      "\t Birmingham\n",
      "\t Ben\n",
      "\t Fed's Plosser\n",
      "\t United States\n",
      "\t 6.2%\n",
      "\t the end of 2014\n"
     ]
    }
   ],
   "source": [
    "print('Entities:')\n",
    "for t in doc:\n",
    "    if t.ent_type_ != '': print('\\t',t,t.ent_type_)\n",
    "\n",
    "print('Noun chunks:')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('\\t',chunk.text, )\n",
    "    #chunk.root.text, chunk.root.dep_,chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben Postance lives in Birmingham.\t>>>\t Ben Postance - lives(VBZ) - Birmingham\n",
      "Ben is about 30 years old.\t>>>\t Ben - is(VBZ) - about 30 years old\n",
      "Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\t>>>\t Fed's Plosser - expects(VBZ) - United States\n",
      "Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\t>>>\t United States - fall(VB) - 6.2%\n"
     ]
    }
   ],
   "source": [
    "for s in doc.sents: \n",
    "    ents = s.ents\n",
    "    if len(ents) > 1:\n",
    "        pairs = [(x,y) for x,y in zip(ents,ents[1:])]\n",
    "        for p in pairs:\n",
    "            for w in doc[p[0].start:p[1].end]:\n",
    "                if w.tag_ in ['VBZ','VBN','VBG','VBD','VB']:\n",
    "                    print(f\"{s}\\t>>>\\t\",f\"{p[0]} - {w}({w.tag_}) - {p[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(doc):\n",
    "    \n",
    "    pre_token=doc[0]\n",
    "    for t in doc:\n",
    "        try:\n",
    "            next_token = doc[t.i+1]\n",
    "        except:\n",
    "            next_token = t\n",
    "\n",
    "        if t.tag_ in ['VBZ','VBN','VBG','VBD','VB']:\n",
    "            if any(re.findall(r'to|in|aux|prep', pre_token.tag_, re.IGNORECASE)):\n",
    "                word = pre_token.text + \" \" + t.text\n",
    "            elif any(re.findall(r'to|in|aux|prep', next_token.tag_, re.IGNORECASE)):\n",
    "                word = t.text + \" \" + next_token.text\n",
    "            else:\n",
    "                word = t.text\n",
    "            return word\n",
    "\n",
    "        pre_token = t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben Postance lives in Birmingham.\t>>>\t Ben Postance - lives in - Birmingham\n",
      "Ben is about 30 years old.\t>>>\t Ben - is - about 30 years old\n",
      "Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\t>>>\t Fed's Plosser - expects - United States\n",
      "Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\t>>>\t United States - to fall - 6.2%\n"
     ]
    }
   ],
   "source": [
    "for s in doc.sents: \n",
    "    ents = s.ents\n",
    "    if len(ents) > 1:\n",
    "        pairs = [(x,y) for x,y in zip(ents,ents[1:])]\n",
    "        for p in pairs:\n",
    "            w = get_relation(doc[p[0].start:p[1].end])\n",
    "            if w is not None: \n",
    "                print(f\"{s}\\t>>>\\t\",f\"{p[0]} - {w} - {p[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014."
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unemployment', 'the end of 2014']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(\"Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expects'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation(\"Fed's Plosser expects United States unemployment to fall to 6.2% by the end of 2014.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "    ## chunk 1\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "\n",
    "    prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "    prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "    prefix = \"\"\n",
    "    modifier = \"\"\n",
    "\n",
    "    #############################################################\n",
    "\n",
    "    for tok in nlp(sent):\n",
    "        ## chunk 2\n",
    "        # if token is a punctuation mark then move on to the next token\n",
    "        if tok.dep_ != \"punct\":\n",
    "            # check: token is a compound word or not\n",
    "            if tok.dep_ == \"compound\":\n",
    "                prefix = tok.text\n",
    "            # if the previous word was also a 'compound' then add the current word to it\n",
    "            if prv_tok_dep == \"compound\":\n",
    "                prefix = prv_tok_text + \" \"+ tok.text\n",
    "\n",
    "          # check: token is a modifier or not\n",
    "        if tok.dep_.endswith(\"mod\") == True:\n",
    "            modifier = tok.text\n",
    "            # if the previous word was also a 'compound' then add the current word to it\n",
    "            if prv_tok_dep == \"compound\":\n",
    "                modifier = prv_tok_text + \" \"+ tok.text\n",
    "\n",
    "          ## chunk 3\n",
    "        if tok.dep_.find(\"subj\") == True:\n",
    "            ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "            prefix = \"\"\n",
    "            modifier = \"\"\n",
    "            prv_tok_dep = \"\"\n",
    "            prv_tok_text = \"\"      \n",
    "\n",
    "        ## chunk 4\n",
    "        if tok.dep_.find(\"obj\") == True:\n",
    "            ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "\n",
    "        ## chunk 5  \n",
    "        # update variables\n",
    "        prv_tok_dep = tok.dep_\n",
    "        prv_tok_text = tok.text\n",
    "        #############################################################\n",
    "\n",
    "    return [ent1.strip(), ent2.strip()]\n",
    "\n",
    "def get_relation(sent):\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Matcher class object \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    #define the pattern \n",
    "    pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "    matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "    matches = matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "\n",
    "    span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "    return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so using NE appears better able to capture our people and organisations. However, naievely creating Triplets by extracting the verbs between Entities is not that good due to:\n",
    " - It fails on complex sentence structures. \n",
    " - It ignores other objects represented by Nouns, Propper Nouns, and Common Nouns etc. \n",
    " - Not all ENTITY types are relevant: PERSON:ORDINAL\n",
    "\n",
    "We could improve some of this by incoporating **[Noun Chunks](https://spacy.io/usage/linguistic-features#noun-chunks)**. You can think of noun chunks as a noun plus the words describing the noun – for example, “the lavish green grass” or “the world’s largest tech fund”.\n",
    "\n",
    "    Text: The original noun chunk text.\n",
    "    Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "    Root dep: Dependency relation connecting the root to its head.\n",
    "    Root head text: The text of the root token’s head.\n",
    "    Children: The immediate syntactic dependents of the root token.\n",
    "    \n",
    " - spaCy uses the terms **head** and **child** to describe the words connected by a single arc in the dependency tree. \n",
    " - The term **dep** is used for the arc label, which describes the type of syntactic relation that connects the child to the head.\n",
    " \n",
    "We can extract further relations by examining the noun modifiers in the noun chunks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other factors to consider:\n",
    "\n",
    " - Ownership: E.g. Noun or Named Entity followed by : [NNS/VBZ](https://sites.google.com/site/partofspeechhelp/home/nns_vbz)\n",
    " - [KG and pruning](http://philipperemy.github.io/information-extract/)\n",
    "  - [git](https://github.com/philipperemy/information-extraction-with-dominating-rules)\n",
    " \n",
    "## References\n",
    "\n",
    " - [OLLIE](https://www.reddit.com/r/LanguageTechnology/comments/bovsf5/we_release_opiec_the_largest_open_information/)\n",
    " - [Clausie](https://github.com/mmxgn/clausiepy)\n",
    " - [Minie](https://github.com/mmxgn/miniepy/graphs/contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
