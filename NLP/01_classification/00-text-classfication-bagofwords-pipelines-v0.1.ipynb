{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    " - [Introductory tutorial](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    " - [Summary of traditional to modern approaches](https://towardsdatascience.com/beyond-word-embeddings-part-2-word-vectors-nlp-modeling-from-bow-to-bert-4ebd4711d0ec)\n",
    "\n",
    "### Multi-Label Classification\n",
    " - [Sklearn package](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    " - [Kaggle examples of common methods](https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm)\n",
    "\n",
    "### Text-Classification using word2vec\n",
    " - [word2vec tutorial](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/)<br>\n",
    " - [deep learning turoial](https://datawarrior.wordpress.com/2016/10/12/short-text-categorization-using-deep-neural-networks-and-word-embedding-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    " - [NLTK Reuters data](https://miguelmalvarez.com/2015/03/20/classifying-reuters-21578-collection-with-python-representing-the-data/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Reuters Data\n",
    "## https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection\n",
    "# !curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/reuters21578-mld/reuters21578.tar.gz\n",
    "# !tar xzvf reuters21578.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [20 News Group data](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=False)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=False)\n",
    "\n",
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {e:v for e,v in enumerate(twenty_train['target_names'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(twenty_train['data']), len(twenty_train['target']), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "def printArticle(n):\n",
    "    global names, twenty_train\n",
    "    target = twenty_train['target'][n]\n",
    "    name = names[target]\n",
    "    doc =  twenty_train['data'][n]\n",
    "    print('{}\\n{}'.format(name,doc))\n",
    "    \n",
    "printArticle(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non alpha-numerical chars, lowercase, strip whitespace\n",
    ".replace('[^a-zA-Z0-9 ]+', ' ', regex=True).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "[Classification reports](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(data):\n",
    "#     X_train, X_test,\\\n",
    "#     y_train, y_test = train_test_split(data['data'],\n",
    "#                                        data['target'],\n",
    "#                                        test_size=0.5,\n",
    "#                                        stratify=data['target'])\n",
    "#     return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "CV = CountVectorizer(strip_accents='unicode',\n",
    "                     lowercase=True,\n",
    "                     stop_words='english',)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "TF = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model param\n",
    "NB_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "             'vect__analyzer':['word','char'],\n",
    "             'tfidf__use_idf':('True'),\n",
    "             'model__alpha':(1e-1, 1e-3)}\n",
    "\n",
    "NB_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('model', MultinomialNB())])\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=NB_pipe,\n",
    "                          param_grid=NB_params,\n",
    "                          n_jobs=-1,\n",
    "                          cv=4)\n",
    "\n",
    "%time gs_NB = gs_NB.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(gs_NB.best_score_, gs_NB.best_params_,'\\n')\n",
    "NBcv_predict = gs_NB.predict(twenty_test['data'])\n",
    "print('NB-CV accuracy: %.3f\\n' %np.mean(NBcv_predict == twenty_test['target']))\n",
    "print(metrics.classification_report(twenty_test['target'],NBcv_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD for SVM & Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model param\n",
    "SVM_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'vect__analyzer':['word','char'],\n",
    "              'tfidf__use_idf':('True'),\n",
    "              'model__loss':('hinge','log'),\n",
    "              'model__alpha':(1e-2, 1e-3),\n",
    "              'model__penalty': ('l2', 'elasticnet'),\n",
    "              'model__max_iter': (100),\n",
    "              'model__tol': (0.21, 1e-3)}\n",
    "\n",
    "SVM_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model',SGDClassifier()),])\n",
    "\n",
    "gs_SVM = GridSearchCV(SVM_pipe,\n",
    "                      param_grid=SVM_params,\n",
    "                      n_jobs=-1,\n",
    "                      cv=4)\n",
    "\n",
    "%time gs_SVM = gs_SVM.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_SVM.best_score_, gs_SVM.best_params_)\n",
    "SVMcv_predict = gs_SVM.predict(twenty_test['data'])\n",
    "\n",
    "print('SVM-CV accuracy: %.3f' %np.mean(SVMcv_predict == twenty_test['target']))\n",
    "print(metrics.classification_report(twenty_test['target'], SVMcv_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot.plotters as skplt\n",
    "skplt.plot_confusion_matrix(twenty_test['target'], SVMcv_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOG_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "#               'tfidf__use_idf':('True','False'),\n",
    "#               'model__alpha':(1e-1, 1e-3)}\n",
    "\n",
    "# LOG_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('model',SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=5, random_state=42)),])\n",
    "\n",
    "# gs_LOG = GridSearchCV(LOG_pipe, param_grid=LOG_params, n_jobs=-1)\n",
    "# gs_LOG = gs_LOG.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(gs_LOG.best_score_, gs_LOG.best_params_)\n",
    "# LOGcv_predict = gs_LOG.predict(twenty_test['data'])\n",
    "# print('LOG-CV accuracy: %.3f' %np.mean(LOGcv_predict, twenty_test['target']))\n",
    "# print(metrics.classification_report(twenty_test['target'], SVMcv_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "ANN_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'vect__analyzer':['word','char'],\n",
    "              'tfidf__use_idf':['True'],\n",
    "              'model__hidden_layer_sizes':[(5,5),(9,5,9)],\n",
    "              'model__alpha':(1e-1, 1e-3),\n",
    "              'model__max_iter': [200],\n",
    "              'model__tol': (1e-1, 1e-3)}\n",
    "\n",
    "ANN_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model',MLPClassifier()),])\n",
    "\n",
    "gs_ANN = GridSearchCV(ANN_pipe,\n",
    "                      param_grid=ANN_params,\n",
    "                      n_jobs=-1,\n",
    "                      cv=4)\n",
    "\n",
    "%time gs_ANN = gs_ANN.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(gs_ANN.best_score_, gs_ANN.best_params_)\n",
    "ANNcv_predict = gs_ANN.predict(twenty_test['data'])\n",
    "print('ANN-CV accuracy: %.3f' %np.mean(ANNcv_predict, twenty_test['target']))\n",
    "print(metrics.classification_report(y_test, SVMcv_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-ranking-metrics\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = r'trainedModels'\n",
    "\n",
    "joblib.dump(gs_NB , os.path.join(model,'gs_NB_1.0.pkl'))\n",
    "#joblib.dump(gs_LOG, model+'gs_LOG_1.0.pkl') \n",
    "joblib.dump(gs_SVM, os.path.join(model,'gs_SVM_1.0.pkl')) \n",
    "joblib.dump(gs_ANN, os.path.join(model,'gs_ANN_1.0.pkl'))\n",
    "\n",
    "# trained-model = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'doc':X_test,\n",
    "                        'target':y_test,\n",
    "                        'NB':NBcv_predict,\n",
    "                        'SVM':SVMcv_predict,\n",
    "                        'LOG':LOGcv_predict,\n",
    "                        'ANN':ANNcv_predict})\n",
    "\n",
    "results = results[['doc','target', 'NB', 'SVM', 'LOG', 'ANN']].copy()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = list(y_test.unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test = label_binarize(y_test, classes=classes)\n",
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM = label_binarize(SVMcv_predict, classes=classes)\n",
    "SVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1, figsize=(7,7))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Test[:, i], SVM[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    axs.plot(fpr[i], tpr[i], label='%s AUC:%.2f'%(c.upper(),roc_auc[i]))\n",
    "    axs.legend()\n",
    "    axs.set_xlim(0,1)\n",
    "    axs.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nltk]",
   "language": "python",
   "name": "conda-env-nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
