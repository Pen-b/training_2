{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b9c1dde0b2464ff6778d75d84efd3ba2ef21848"
   },
   "source": [
    "\n",
    "## [spaCy : Faster Natural Language Processing Toolkit](https://www.kaggle.com/shivamb/spacy-text-meta-features-knowledge-graphs)\n",
    "\n",
    "\n",
    "\n",
    "### Quick Intro\n",
    "\n",
    "Spacy is written in cython language, (C extension of Python designed to give C like performance to the python program). Hence is a quite fast library. spaCy provides a concise API to access its methods and properties governed by trained machine (and deep) learning models. For a detailed information, one can refer to my blog on spaCy that I wrote in 2017 :\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/\n",
    "\n",
    "\n",
    "Different types of features can be generated from the text data. For example - \n",
    "\n",
    "Count Features : Word counts, Character Counts, Punctuation Counts, Stopwords. \n",
    "NLP Attributes : Part of speech tags distribution, grammar relations as features, topic models \n",
    "Word Vectors : TF-IDF, Count Vectors, Word Embeddings  \n",
    "\n",
    "### Uses of meta features of text:  \n",
    "\n",
    "1. Information Extraction   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Social Media  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Chats & Conversations  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 1.3 News / Articles     \n",
    "2. Machine Learning Models  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Classification / Regression Models     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Recommendation Models     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 2.3. Building Knowledge Graphs  \n",
    "\n",
    "\n",
    "In this kernel, I have shared a framework that uses spacy which can be used to automatically different types of features from a given text. Importing the required libraries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85600930b325b2bc99c604b7535cf298e475c247"
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import pandas as pd\n",
    "import spacy \n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b23103283c0efb1de3b67f44d0da64853fce5787"
   },
   "source": [
    "Next, lets define the class that will use spacy functions to generate features . In the class, initialize some important variables and lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_kg_hide-input": false,
    "_uuid": "f97c8c7c3a2dd72fd56f053c59081398d4012d36"
   },
   "outputs": [],
   "source": [
    "feats = ['char_count', 'word_count', 'word_count_cln',\n",
    "       'stopword_count', '_NOUN', '_VERB', '_ADP', '_ADJ', '_DET', '_PROPN',\n",
    "       '_INTJ', '_PUNCT', '_NUM', '_PRON', '_ADV', '_PART', '_amod', '_ROOT',\n",
    "       '_punct', '_advmod', '_auxpass', '_nsubjpass', '_ccomp', '_acomp',\n",
    "       '_neg', '_nsubj', '_aux', '_agent', '_det', '_pobj', '_prep', '_csubj',\n",
    "       '_nummod', '_attr', '_acl', '_relcl', '_dobj', '_pcomp', '_xcomp',\n",
    "       '_cc', '_conj', '_mark', '_prt', '_compound', '_dep', '_advcl',\n",
    "       '_parataxis', '_poss', '_intj', '_appos', '_npadvmod', '_predet',\n",
    "       '_case', '_expl', '_oprd', '_dative', '_nmod']\n",
    "\n",
    "class AutomatedTextFE:\n",
    "    def __init__(self):\n",
    "        self.pos_tags = ['NOUN', 'VERB', 'ADP', 'ADJ', 'DET', 'PROPN', 'INTJ', 'PUNCT',\\\n",
    "                         'NUM', 'PRON', 'ADV', 'PART']\n",
    "        self.dep_tags = ['amod', 'ROOT', 'punct', 'advmod', 'auxpass', 'nsubjpass',\\\n",
    "                         'ccomp', 'acomp', 'neg', 'nsubj', 'aux', 'agent', 'det', 'pobj',\\\n",
    "                         'prep', 'csubj', 'nummod', 'attr', 'acl', 'relcl', 'dobj', 'pcomp', \\\n",
    "                         'xcomp', 'cc', 'conj', 'mark', 'prt', 'compound', 'dep', 'advcl',\\\n",
    "                         'parataxis', 'poss', 'intj', 'appos', 'npadvmod', 'predet', 'case',\\\n",
    "                         'expl', 'oprd', 'dative', 'nmod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7fcde2feeae77b919d0ca2ca8f053bc9bc71855"
   },
   "source": [
    "Adding a text cleaning function that removes stopwords, punctuations, performs normalization (lemmatization) and lower cases the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ecf6976c6ab9b2bea87bab7aa48ee9a605450c34"
   },
   "outputs": [],
   "source": [
    "def _spacy_cleaning(doc):\n",
    "    toks = [t for t in doc if (t.is_stop == False)]\n",
    "    toks = [t for t in toks if (t.is_punct == False)]\n",
    "    words = [t.lemma_ for token in toks]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0de615940556d7906b02f985d7bc2a36ed8d1dfd"
   },
   "source": [
    "Next, lets write the function to perform feature engineering. This function will extract following:\n",
    "\n",
    "- word counts, char counts, stopword counts   \n",
    "- part of speech tags and their counts  \n",
    "- dependency relations among words and their counts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7513a1f85631147587d9678c2308ef7cf93f1e4"
   },
   "outputs": [],
   "source": [
    "def _spacy_features(df):\n",
    "    df[\"clean_text\"] = df[c].apply(lambda x : _spacy_cleaning(x))\n",
    "    df[\"char_count\"] = df[textcol].apply(len)\n",
    "    df[\"word_count\"] = df[c].apply(lambda x : len([_ for _ in x]))\n",
    "    df[\"word_count_cln\"] = df[\"clean_text\"].apply(lambda x : len(x.split()))\n",
    "    df[\"stopword_count\"] = df[c].apply(lambda x : len([_ for _ in x if _.is_stop]))\n",
    "    df[\"pos_tags\"] = df[c].apply(lambda x : dict(Counter([_.head.pos_ for _ in x])))\n",
    "    df[\"dep_tags\"] = df[c].apply(lambda x : dict(Counter([_.dep_ for _ in x])))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3870e1e4a52f8cb59f0254979c1328ec8294de34"
   },
   "source": [
    "Next, lets wrap this functions in the main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "572b91cd3c32bc1a15fd16982e9216428812b468"
   },
   "outputs": [],
   "source": [
    "class AutomatedTextFE:\n",
    "    def __init__(self, df, textcol):\n",
    "        self.df = df\n",
    "        self.textcol = textcol\n",
    "        self.c = \"spacy_\" + textcol\n",
    "        self.df[self.c] = self.df[self.textcol].apply( lambda x : nlp(x))\n",
    "        \n",
    "        self.pos_tags = ['NOUN', 'VERB', 'ADP', 'ADJ', 'DET', 'PROPN', 'INTJ', 'PUNCT',\\\n",
    "                         'NUM', 'PRON', 'ADV', 'PART']\n",
    "        self.dep_tags = ['amod', 'ROOT', 'punct', 'advmod', 'auxpass', 'nsubjpass',\\\n",
    "                         'ccomp', 'acomp', 'neg', 'nsubj', 'aux', 'agent', 'det', 'pobj',\\\n",
    "                         'prep', 'csubj', 'nummod', 'attr', 'acl', 'relcl', 'dobj', 'pcomp', \\\n",
    "                         'xcomp', 'cc', 'conj', 'mark', 'prt', 'compound', 'dep', 'advcl',\\\n",
    "                         'parataxis', 'poss', 'intj', 'appos', 'npadvmod', 'predet', 'case',\\\n",
    "                         'expl', 'oprd', 'dative', 'nmod']\n",
    "        \n",
    "    def _spacy_cleaning(self, doc):\n",
    "        tokens = [token for token in doc if (token.is_stop == False)\\\n",
    "                  and (token.is_punct == False)]\n",
    "        words = [token.lemma_ for token in tokens]\n",
    "        return \" \".join(words)\n",
    "        \n",
    "    def _spacy_features(self):\n",
    "        self.df[\"clean_text\"] = self.df[self.c].apply(lambda x : self._spacy_cleaning(x))\n",
    "        self.df[\"char_count\"] = self.df[self.textcol].apply(len)\n",
    "        self.df[\"word_count\"] = self.df[self.c].apply(lambda x : len([_ for _ in x]))\n",
    "        self.df[\"word_count_cln\"] = self.df[\"clean_text\"].apply(lambda x : len(x.split()))\n",
    "        \n",
    "        self.df[\"stopword_count\"] = self.df[self.c].apply(lambda x : \n",
    "                                                          len([_ for _ in x if _.is_stop]))\n",
    "        self.df[\"pos_tags\"] = self.df[self.c].apply(lambda x :\n",
    "                                                    dict(Counter([_.head.pos_ for _ in x])))\n",
    "        self.df[\"dep_tags\"] = self.df[self.c].apply(lambda x :\n",
    "                                                    dict(Counter([_.dep_ for _ in x])))\n",
    "        \n",
    "    def _flatten_features(self):\n",
    "        for key in self.pos_tags:\n",
    "            self.df[\"_\" + key] = self.df[\"pos_tags\"].apply(lambda x : \\\n",
    "                                                           x[key] if key in x else 0)\n",
    "        \n",
    "        for key in self.dep_tags:\n",
    "            self.df[\"_\" + key] = self.df[\"dep_tags\"].apply(lambda x : \\\n",
    "                                                           x[key] if key in x else 0)\n",
    "                \n",
    "    def generate_features(self):\n",
    "        self._spacy_features()\n",
    "        self._flatten_features()\n",
    "        self.df = self.df.drop([self.c, \"pos_tags\", \"dep_tags\", \"clean_text\"], axis=1)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9886961f1222adac518698d52e160888fad6c903"
   },
   "source": [
    "Finally, create a wrapper function which can be used to call the specific functions for feature generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f720050c0f6df106a516a674cbca0e16b89a6a07"
   },
   "outputs": [],
   "source": [
    "def spacy_features(df, tc):\n",
    "    fe = AutomatedTextFE(df, tc)\n",
    "    return fe.generate_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "864ba036830e3225141dccbbb9b1fddac16577c0"
   },
   "source": [
    "Let's look at some examples: \n",
    "\n",
    "### Ted Talk Transcripts Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "890f4043c01ebe552f4a8cdada8f66374d9fcfe7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"../input/ted-talks/transcripts.csv\"\n",
    "df = pd.read_csv(path)[:10]\n",
    "textcol = \"transcript\"\n",
    "\n",
    "feats_df = spacy_features(df, textcol)\n",
    "feats_df[[textcol] + feats].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e97af825c09b52f31cd03e5e59c4a62dce766ab"
   },
   "source": [
    "### Seinfeld Chronicles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5310f8b42ed0de2a5e5a77f62820d17de77cb26"
   },
   "outputs": [],
   "source": [
    "path = \"../input/seinfeld-chronicles/scripts.csv\"\n",
    "df = pd.read_csv(path)[:10]\n",
    "textcol = \"Dialogue\"\n",
    "\n",
    "feats_df = spacy_features(df, textcol)\n",
    "feats_df[[textcol] + feats].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56cdec5c70d72fc837d597407ea6582e34e15781"
   },
   "source": [
    "So these features can be passed to ML model for better classification, or can be used in recommendation engines to improve recommendations. Other use-cases can be to improve the search results, chat bot responses, and better information reterival."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
