{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Chapter 4](https://course.spacy.io/chapter4)\n",
    "\n",
    "In this chapter, you'll learn how to update spaCy's statistical models to customize them for your use case – for example, to predict a new entity type in online comments. You'll write your own training loop from scratch, and understand the basics of how training works, along with tips and tricks that can make your custom NLP projects more successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "\n",
    "# $ python -m spacy download en_core_web_sm\n",
    "# $ python -m spacy download en_core_web_md\n",
    "# $ python -m spacy download en_core_web_lg\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "The training data are the examples we want to update the model with.\n",
    "The text should be a sentence, paragraph or longer document. For the best results, it should be similar to what the model will see at runtime.\n",
    "The label is what we want the model to predict. This can be a text category, or an entity span and its type.\n",
    "The gradient is how we should change the model to reduce the current error. It's computed when we compare the predicted label to the true label.\n",
    "After training, we can then save out an updated model and use it in our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://course.spacy.io/training.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://course.spacy.io/training.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Match Rules To Create Training Data\n",
    "\n",
    "Let’s use some match patterns we’ve created to bootstrap a set of training examples. A list of sentences is available as the variable TEXTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"exercises/iphone.json\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)\n",
    "\n",
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Training a Model\n",
    "\n",
    "Let’s write a simple training loop from scratch!\n",
    "The pipeline you’ve created in the previous exercise is available as the nlp object. It already contains the entity recognizer with the added label 'GADGET'.\n",
    "The small set of labelled examples that you’ve created previously is available as TRAINING_DATA. To see the examples, you can print them in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 11.199999451637268}\n",
      "{'ner': 22.608760356903076}\n",
      "{'ner': 31.69031023979187}\n",
      "{'ner': 7.134791314601898}\n",
      "{'ner': 14.171489298343658}\n",
      "{'ner': 17.40808865427971}\n",
      "{'ner': 1.6917238347232342}\n",
      "{'ner': 6.152672458440065}\n",
      "{'ner': 9.372104265145026}\n",
      "{'ner': 1.4761813097284175}\n",
      "{'ner': 3.3679748892900534}\n",
      "{'ner': 4.7345728858344955}\n",
      "{'ner': 2.1268748844740912}\n",
      "{'ner': 5.620544813456945}\n",
      "{'ner': 8.640644057071768}\n",
      "{'ner': 2.457177545875311}\n",
      "{'ner': 5.079249800299294}\n",
      "{'ner': 5.84424194006715}\n",
      "{'ner': 1.4112991895526648}\n",
      "{'ner': 1.7581186078023165}\n",
      "{'ner': 3.6494354910682887}\n",
      "{'ner': 1.1694431360810995}\n",
      "{'ner': 2.290436919418653}\n",
      "{'ner': 2.3815858341684475}\n",
      "{'ner': 0.7015699759685994}\n",
      "{'ner': 0.7040331653881857}\n",
      "{'ner': 0.7151841569083383}\n",
      "{'ner': 0.0001465689825774774}\n",
      "{'ner': 2.1335694881336122}\n",
      "{'ner': 2.135355341445235}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"exercises/gadgets.json\") as f:\n",
    "    TRAINING_DATA = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "ner.add_label(\"GADGET\")\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training Best Practice:\n",
    "\n",
    "1. If you're updating an existing model with new data, especially new labels, it can overfit and adjust too much to the new examples. or instance, if you're only updating it with examples of \"website\", it may \"forget\" other labels it previously predicted correctly – like \"person\". his is also known as the catastrophic forgetting problem.\n",
    " - To prevent this, make sure to always mix in examples of what the model previously got correct.\n",
    "1. Another common problem is that your model just won't learn what you want it to.For example, it may be very difficult to teach a model to predict whether something is adult clothing or children's clothing based on the context. However, just predicting the label \"clothing\" may work better.\n",
    " - Before you start training and updating models, it's worth taking a step back and planning your label scheme. ry to pick categories that are reflected in the local context and make them more generic if possible. You can always add a rule-based system later to go from generic to specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
