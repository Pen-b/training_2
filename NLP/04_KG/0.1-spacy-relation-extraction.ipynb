{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***installing Spacy 2.1.0***\n",
    "\n",
    "neuralcoref only works with Spacy, 2.1.0. Whilst spacy can be installe dusing Pip or Conda, to install the lg english model I had to:\n",
    "- https://v2.spacy.io/models/en\n",
    "- manually download the tar https://github.com/explosion/spacy-models/releases//tag/en_core_web_lg-2.3.1#\n",
    "- and install locally as described here https://github.com/explosion/spaCy/issues/4577\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "import neuralcoref #\n",
    "from spacy import displacy\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "except:\n",
    "    !python -m spacy download en_core_web_lg\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tesco has been hit by hackers, leaving thousan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The outage leaves its grocery website and app ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  Tesco has been hit by hackers, leaving thousan...\n",
       "1   1  The outage leaves its grocery website and app ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('tesco.xlsx',skiprows=2)\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- [coreference resolution](https://spacy.io/universe/project/neuralcoref)\n",
    "- [named entity recognition]()\n",
    " \n",
    "<img src=\"./model_architecture.svg\" width=400 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "To extract the named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "df['text-clean'] = df['text'].apply(lambda x: re.sub(r\"(\\w+)'s\", r'\\1s', x))\n",
    "\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer NER\n",
    "try:\n",
    "    nlp.remove_pipe('entity_ruler')\n",
    "except:\n",
    "    config = {\n",
    "       \"phrase_matcher_attr\": None,\n",
    "       \"validate\": True,\n",
    "       \"overwrite_ents\": True,\n",
    "       \"ent_id_sep\": \"||\",\n",
    "    }\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", config=config)\n",
    "    patterns = [\n",
    "                {'label': 'GROUP', 'pattern': [{'TEXT': {'REGEX': r'(?i)(?i)(customer)s?' }} ]},\n",
    "                {'label': 'GROUP', 'pattern': [{'TEXT': {'REGEX': r'(?i)(?i)(shopper)s?' }} ]},\n",
    "                {'label': 'GROUP', 'pattern': [{'TEXT': {'REGEX': r'(?i)(?i)(hacker)s?' }} ]},\n",
    "                ]\n",
    "    ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply nlp\n",
    "df['doc'] = df['text-clean'].apply(lambda x: nlp(x))\n",
    "spacy.displacy.render(df['doc'][1], style='ent')\n",
    "spacy.displacy.render(df['doc'][1], style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the entities and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example doc\n",
    "doc = df['doc'][0]\n",
    "# doc = nlp(\"Ben was born in Hawaii. He owns two cats\")\n",
    "for tok in doc:\n",
    "    if tok.pos_ in ['PROPN','NOUN','PRON']:\n",
    "        print((tok.text.title(),tok.pos_,tok.dep_,tok.ent_type_,tok.i,tok.idx))\n",
    "    else:\n",
    "        print('\\t',(tok.text.title(),tok.pos_,tok.dep_,tok.ent_type_,tok.i,tok.idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get entities\n",
    "def get_entities(doc):\n",
    "    entities = dict()\n",
    "    for tok in doc:\n",
    "        if tok.pos_ in ['PROPN','NOUN','PRON']:\n",
    "            entities[tok.i] = tok # token.i is int location in doc\n",
    "            # print((tok.text.title(),tok.pos_,tok.dep_,tok.ent_type_,tok.i,tok.idx))\n",
    "    return entities\n",
    "\n",
    "entities = get_entities(doc)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ordered entity pairs\n",
    "def get_entity_pairs(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return {e:{'from':x[0],'to':x[1]} for e,x in enumerate(zip(a, b))}\n",
    "entity_pairs = get_entity_pairs(entities.keys())\n",
    "entity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge text\n",
    "def get_entity_edges(entity_pairs):\n",
    "    for k in list(entity_pairs.keys()):\n",
    "        v = entity_pairs[k]\n",
    "        edge_text = [t.text for t in doc[v['from']:v['to']+1] if t.pos_ in ['VERB','ADP','ADJ']]\n",
    "        edge_text = ' '.join(edge_text)\n",
    "        if len(edge_text) == 0:\n",
    "            del entity_pairs[k]\n",
    "        else:\n",
    "            v['edge'] = edge_text\n",
    "    \n",
    "get_entity_edges(entity_pairs)\n",
    "entity_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view relations between entities and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "G=nx.Graph(name='simple KG')\n",
    "\n",
    "for k,node in entities.items():\n",
    "    G.add_node(k,name=node.text.title(), ent_typ=node.ent_type_, pos=node.pos_) \n",
    "node_labels = {node[0]:node[1]['name'] for node in G.nodes(data=True)}\n",
    "\n",
    "edges = [(v['from'],v['to'],{'weight':1}) for v in entity_pairs.values()]\n",
    "edge_labels = {(v['from'],v['to']):v['edge'] for v in entity_pairs.values()}\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "fig,ax = plt.subplots(1,1, figsize=(10,10))\n",
    "pos = nx.spring_layout(G,seed=10)\n",
    "nx.draw(G, \n",
    "        ax=ax,\n",
    "        pos=pos,\n",
    "        labels=node_labels,\n",
    "        width=0.1)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,\n",
    "                             pos,\n",
    "                             edge_labels=edge_labels,\n",
    "                             font_color='red')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
